{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab Tasks\n",
    "- In the dataframe creates in Lab 2 - Part a set ``Salary`` as the target value. \n",
    "- The rest of the columns are considered as X, feature set. \n",
    "- Use ``train_test_split`` to split the dataset into train and test dataset. set ``random_state = 0``.\n",
    "- Use ``MinMaxScaler`` to scale feature set X. \n",
    "\n",
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "data = pd.read_csv('adult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data != ' ?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['workclass', 'education', 'occupation', 'native-country']\n",
    "data.drop(l, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(data['marital-status'])\n",
    "data = pd.concat([data, df], axis = 1)\n",
    "data.drop('marital-status', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(data['relationship'])\n",
    "data = pd.concat([data, df], axis = 1)\n",
    "data.drop('relationship', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(data['race'])\n",
    "data = pd.concat([data, df], axis = 1)\n",
    "data.drop('race', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'fnlwgt', 'education-num', 'sex', 'capital-gain', 'capital-loss',\n",
       "       'hours-per-week', 'Salary', ' Divorced', ' Married-AF-spouse',\n",
       "       ' Married-civ-spouse', ' Married-spouse-absent', ' Never-married',\n",
       "       ' Separated', ' Widowed', ' Husband', ' Not-in-family',\n",
       "       ' Other-relative', ' Own-child', ' Unmarried', ' Wife',\n",
       "       ' Amer-Indian-Eskimo', ' Asian-Pac-Islander', ' Black', ' Other',\n",
       "       ' White'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sex'] = data['sex'].map({' Male':0, ' Female':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Salary'] = data['Salary'].map({' <=50K':0, ' >50K':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1\n",
    "First train the following models on X_train and y_train. \n",
    "- Linear support vector machine with default parameters. \n",
    "- decision tree with ``max_depth = 3``\n",
    "- K neighbors classifier with ``n_neighbors = 5``.\n",
    "\n",
    "In the all above models, set ``random_sate = 0``.\n",
    "Compute the test precision score of hard-voting classifier? (two significant digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 25 columns):\n",
      "age                       32561 non-null int64\n",
      "fnlwgt                    32561 non-null int64\n",
      "education-num             32561 non-null int64\n",
      "sex                       32561 non-null int64\n",
      "capital-gain              32561 non-null int64\n",
      "capital-loss              32561 non-null int64\n",
      "hours-per-week            32561 non-null int64\n",
      " Divorced                 32561 non-null uint8\n",
      " Married-AF-spouse        32561 non-null uint8\n",
      " Married-civ-spouse       32561 non-null uint8\n",
      " Married-spouse-absent    32561 non-null uint8\n",
      " Never-married            32561 non-null uint8\n",
      " Separated                32561 non-null uint8\n",
      " Widowed                  32561 non-null uint8\n",
      " Husband                  32561 non-null uint8\n",
      " Not-in-family            32561 non-null uint8\n",
      " Other-relative           32561 non-null uint8\n",
      " Own-child                32561 non-null uint8\n",
      " Unmarried                32561 non-null uint8\n",
      " Wife                     32561 non-null uint8\n",
      " Amer-Indian-Eskimo       32561 non-null uint8\n",
      " Asian-Pac-Islander       32561 non-null uint8\n",
      " Black                    32561 non-null uint8\n",
      " Other                    32561 non-null uint8\n",
      " White                    32561 non-null uint8\n",
      "dtypes: int64(7), uint8(18)\n",
      "memory usage: 2.3 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>Divorced</th>\n",
       "      <th>Married-AF-spouse</th>\n",
       "      <th>Married-civ-spouse</th>\n",
       "      <th>...</th>\n",
       "      <th>Not-in-family</th>\n",
       "      <th>Other-relative</th>\n",
       "      <th>Own-child</th>\n",
       "      <th>Unmarried</th>\n",
       "      <th>Wife</th>\n",
       "      <th>Amer-Indian-Eskimo</th>\n",
       "      <th>Asian-Pac-Islander</th>\n",
       "      <th>Black</th>\n",
       "      <th>Other</th>\n",
       "      <th>White</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  fnlwgt  education-num  sex  capital-gain  capital-loss  \\\n",
       "0   39   77516             13    0          2174             0   \n",
       "1   50   83311             13    0             0             0   \n",
       "2   38  215646              9    0             0             0   \n",
       "3   53  234721              7    0             0             0   \n",
       "4   28  338409             13    1             0             0   \n",
       "\n",
       "   hours-per-week   Divorced   Married-AF-spouse   Married-civ-spouse   ...    \\\n",
       "0              40          0                   0                    0   ...     \n",
       "1              13          0                   0                    1   ...     \n",
       "2              40          1                   0                    0   ...     \n",
       "3              40          0                   0                    1   ...     \n",
       "4              40          0                   0                    1   ...     \n",
       "\n",
       "    Not-in-family   Other-relative   Own-child   Unmarried   Wife  \\\n",
       "0               1                0           0           0      0   \n",
       "1               0                0           0           0      0   \n",
       "2               1                0           0           0      0   \n",
       "3               0                0           0           0      0   \n",
       "4               0                0           0           0      1   \n",
       "\n",
       "    Amer-Indian-Eskimo   Asian-Pac-Islander   Black   Other   White  \n",
       "0                    0                    0       0       0       1  \n",
       "1                    0                    0       0       0       1  \n",
       "2                    0                    0       0       0       1  \n",
       "3                    0                    0       1       0       0  \n",
       "4                    0                    0       1       0       0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Salary, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.loc[:, data.columns != 'Salary']\n",
    "y = data['Salary']\n",
    "X.info()\n",
    "X.head()\n",
    "y.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_orig, X_test_orig, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train_orig)\n",
    "X_test = scaler.transform(X_test_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mglearn in c:\\users\\srohi\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (0.1.7)\n",
      "Requirement already satisfied: cycler in c:\\users\\srohi\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from mglearn) (0.10.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\srohi\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from mglearn) (2.2.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\srohi\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from mglearn) (5.4.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\srohi\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from mglearn) (0.19.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\srohi\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from mglearn) (1.14.3)\n",
      "Requirement already satisfied: imageio in c:\\users\\srohi\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from mglearn) (2.3.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\srohi\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from mglearn) (0.23.0)\n",
      "Requirement already satisfied: six in c:\\users\\srohi\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from cycler->mglearn) (1.11.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\srohi\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from matplotlib->mglearn) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\srohi\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from matplotlib->mglearn) (2.7.3)\n",
      "Requirement already satisfied: pytz in c:\\users\\srohi\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from matplotlib->mglearn) (2018.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\srohi\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from matplotlib->mglearn) (1.0.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\srohi\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib->mglearn) (39.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 18.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install mglearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient Shape:  (1, 25)\n",
      "Intercept Shape:  (1,)\n",
      "Training Set Accuracy: 0.84\n",
      "Testing Set Accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "#Linear Support Vector Machine\n",
    "from sklearn.svm import LinearSVC\n",
    "linear_svm = LinearSVC(random_state = 0).fit(X_train, y_train)\n",
    "print('Coefficient Shape: ', linear_svm.coef_.shape)\n",
    "print('Intercept Shape: ', linear_svm.intercept_.shape)\n",
    "print('Training Set Accuracy: {:.2f}'.format(linear_svm.score(X_train, y_train)))\n",
    "print('Testing Set Accuracy: {:.2f}'.format(linear_svm.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy: 0.84\n",
      "Testing Set Accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dec_tree = DecisionTreeClassifier(max_depth = 3, random_state = 0)\n",
    "dec_tree.fit(X_train, y_train)\n",
    "print('Training Set Accuracy: {:.2f}'.format(dec_tree.score(X_train, y_train)))\n",
    "print('Testing Set Accuracy: {:.2f}'.format(dec_tree.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=2, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=4, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=6, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=9, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=11, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=12, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=13, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=14, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=16, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=17, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=18, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=19, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#K Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "training_score_list = []\n",
    "testing_score_list = []\n",
    "\n",
    "for k in range(1, 20):\n",
    "    knn = KNeighborsClassifier(k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    training_score_list.append(knn.score(X_train, y_train))\n",
    "    testing_score_list.append(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1bb9dc9da20>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1bb9d90df60>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'k value')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Accuracy')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1bb9dc9dc88>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8VPW9//HXJyEhCUsSsrCvgkoyYU3B7efSUgRs9bqCW3FprVbrctvba5WqlS7Wem/Vi1cvveLegtXWa1utiq211VIWZUf2LWwJCQQMgWSS7++PM0kmYcJMQiaT5f18PM5jzj6fHMK8c875zveYcw4REZETiYt1ASIi0vYpLEREJCyFhYiIhKWwEBGRsBQWIiISlsJCRETCUliIiEhYCgsREQlLYSEiImF1iXUBLSUzM9MNGTIk1mWIiLQry5Yt2++cywq3XocJiyFDhrB06dJYlyEi0q6Y2fZI1tNlKBERCUthISIiYSksREQkrA5zz0JE2p/KykoKCgo4evRorEvp8JKSkhgwYAAJCQnN2j5qYWFm84CvAIXOOV+I5QY8AUwDjgA3OOc+CSybCcwKrPoj59wL0apTRGKnoKCAHj16MGTIELyPBIkG5xzFxcUUFBQwdOjQZu0jmpehngemnGD5VGBEYLgFeBrAzHoBDwITgQnAg2aWHsU6RSRGjh49SkZGhoIiysyMjIyMkzqDi1pYOOc+BEpOsMolwIvOswhIM7O+wIXAe865EufcAeA9Thw6ItKOKShax8ke51je4O4P7AyaLgjMa2x+VBwoP8Dsv85m6W59R0NEpDGxDItQMedOMP/4HZjdYmZLzWxpUVFRs4qIj4vngQ8e4L3N7zVrexFpv4qLixkzZgxjxoyhT58+9O/fv3a6oqIion3ceOONrF+/PuL33LNnD9OmTWP06NHk5ORw8cUXN7f8VhXL1lAFwMCg6QHA7sD88xvM/yDUDpxzc4G5APn5+SEDJZyeXXsyKHUQq4tWN2dzEWnHMjIyWL58OQAPPfQQ3bt357vf/W69dZxzOOeIiwv9t/Vzzz3XpPecNWsWF110EbfffjsAK1eubEbl9fn9frp0ie7HeSzPLN4EvmaeM4BS59we4B1gspmlB25sTw7Mixpfto/VhQoLEfFs2rQJn8/Hrbfeyrhx49izZw+33HIL+fn55Obm8vDDD9eue84557B8+XL8fj9paWnce++9jB49mjPPPJPCwsLj9r1nzx4GDBhQOz1q1Kja8Z/85Cfk5eUxevRo7r//fgA++eQTJk6cyKhRo7j88sspLS2tfd/777+fc889lzlz5rBv3z4uu+wy8vPzmTBhAosWLWrRYxLNprO/xjtDyDSzArwWTgkAzrlngLfwms1uwms6e2NgWYmZzQaWBHb1sHPuRDfKT5ovy8fCLQuprKokIb55bZBF5OTc/ae7Wb53eYvuc0yfMTw+5fFmbbt27Vqee+45nnnmGQAeeeQRevXqhd/v54ILLuCKK64gJyen3jalpaWcd955PPLII/zrv/4r8+bN49577623zh133ME111zDuHHjmDRpEjfeeCN9+/bl97//PW+//TaLFy8mOTmZkhLvY++6665j7ty5nHPOOdx3333Mnj2bxx57DIBDhw7x4YcfAjB9+nS+973vccYZZ7Bt2za+8pWvsHp1y/0RHLWwcM5dHWa5A25vZNk8YF406grFl+2joqqCTSWbGJk1srXeVkTasFNOOYUvfOELtdO//vWvefbZZ/H7/ezevZu1a9ceFxbJyclMnToVgPHjx/O3v/3tuP1OmzaNzZs386c//Ym3336bsWPHsmbNGhYuXMhNN91EcnIyAL169aK4uJijR49yzjnnADBz5kyuv/762n3NmDGjdnzhwoX17p0cOHCA8vLy2v2dLH2DGy8sAFYXrlZYiMRIc88AoqVbt2614xs3buSJJ55g8eLFpKWlcd1114X8zkJiYmLteHx8PH6/P+S+MzIyuPbaa7n22muZMmUKf//733HOHde81fubOrIanXMsXry4Xg0tSX1DAadnnk6cxem+hYiEdOjQIXr06EHPnj3Zs2cP77zT/Nuo77//PuXl5bX73bp1K4MGDWLy5Mk8++yztctKSkrIzMwkOTmZjz/+GICXXnqJ8847L+R+J02axFNPPVU7XXPjvqXozAJITkhmeK/hrCpcFetSRKQNGjduHDk5Ofh8PoYNG8bZZ5/d7H0tWbKEO+64g4SEBKqrq7ntttsYO3YsY8eOZcWKFeTn55OQkMBXv/pVZs+ezUsvvcRtt91GeXk5w4cPb7T11VNPPcVtt93Gc889V3tfJTg8TpaFO81pL/Lz893JPPzo8lcvZ9W+VWz49oYWrEpETmTdunWMHKlLv60l1PE2s2XOufxw2+oyVEBedh6bSjZRXlke61JERNochUWAL9uHw7Fu/7pYlyIi0uYoLAKCW0SJiEh9CouA4b2GkxifqLAQEQlBYRHQJa4LIzNHKixEREJQWARRH1EiIqEpLIL4sn3sPLST0qOlsS5FRFpBS3RRDjBv3jz27t0bctlHH33ExIkTGTNmDCNHjmT27NktVX6r0pfygtTc5F5TtIazBp4V42pEJNoi6aI8EvPmzWPcuHH06dPnuGUzZ87kjTfewOfzUVVV1aRnXzSmqqqK+Pj4k95PU+jMIohaRIlIjRdeeIEJEyYwZswYvvWtb1FdXY3f7+f6668nLy8Pn8/Hk08+yYIFC1i+fDnTp08PeUZSVFRUGyLx8fG1nQ8ePnyYmTNnkpeXx6hRo3jjjTcAePnll2v3f9999wHUdn8+a9YsJkyYwOLFi1myZAnnnXce48ePZ+rUqezbty+qx0NnFkEGpQ6ie2J3hYVIDNx9N7Rwd0aMGQOPN6N/wtWrV/O73/2Ojz/+mC5dunDLLbcwf/58TjnlFPbv38+qVV7XQAcPHiQtLY3/+q//Ys6cOYwZM+a4fd19992MGDGCCy64gKlTp/K1r32Nrl278tBDD5GVlcWqVatwznHw4EEKCgqYNWsWS5cuJTU1lUmTJvGHP/yBKVOmUFpayrhx4/jRj37EsWPHuOCCC3jzzTfJzMzklVde4Qc/+AFz58492UPWKIVFkDiLIzcrV2Eh0sktXLiQJUuWkJ/v9YJRXl7OwIEDufDCC1m/fj133XUX06ZNY/LkyWH39cMf/pDrr7+ed999lxdffJEFCxawcOFCFi5cWHs2YWakp6fz5z//mS9+8YtkZmYCcM011/Dhhx8yZcoUEhMTufTSSwGv2441a9YwadIkwLssFfxApWhQWDSQl53HG+vfCNldsIhET3POAKLFOcdNN90U8mb0ypUrefvtt3nyySd5/fXXI/prfvjw4QwfPpxvfOMbZGRkUFpa2uQuyZOTk2vXd84xatSokM/LiBbds2jAl+1j/5H9FJYd/zhEEekcJk2axKuvvsr+/fsBr9XUjh07KCoqwjnHlVdeyQ9/+EM++eQTAHr06MHhw4dD7uuPf/xjbQhs2LCBrl270qNHDyZPnsycOXMA78P/wIEDnHHGGfzlL3+huLgYv9/P/PnzQ3ZJnpOTw65du1i8eDEAFRUVrFmzpsWPQzCdWTQQfJO7d/feMa5GRGIhLy+PBx98kEmTJlFdXU1CQgLPPPMM8fHx3HzzzbVnBT/72c8AuPHGG/n6179OcnLycQ8gev7557nnnntISUkhISGBX/3qV8TFxfHggw/yrW99C5/PR3x8PLNnz+biiy/m4Ycf5vzzz8c5x1e/+lUuuuii4x6i1LVrV1577TXuvPNODh8+jN/v5zvf+Q65ublROybqoryBfZ/vo89/9OHxCx/nrjPuaoHKRKQx6qK8damL8haU3S2bzJRM3eQWEQmisGjAzLxuP4oUFiIiNRQWIfiyvD6iOsolOpG2TP/PWsfJHmeFRQi+bB+fV3zOjtIdsS5FpENLSkqiuLhYgRFlzjmKi4tJSkpq9j7UGiqE4BZRg9MGx7gakY5rwIABFBQUUFRUFOtSOrykpKST+uKewiKE3Gyv+dnqwtVcdOpFMa5GpONKSEhg6NChsS5DIqDLUCGkJaUxsOdA3eQWEQlQWDRCD0ISEamjsGiEL9vHuqJ1+Kv94VcWEengFBaN8GX7OFZ1jE0lm2JdiohIzCksGqEHIYmI1FFYNGJk5kgMU1iIiKCwaFRyQjLDew1XWIiIoLA4IbWIEhHxKCxOwJftY2PJRo76j8a6FBGRmFJYnIAv20e1q+az/Z/FuhQRkZhSWJyAWkSJiHgUFicwotcIEuMTFRYi0ukpLE4gIT6B0zNPV1iISKensAhDLaJERKIcFmY2xczWm9kmM7s3xPLBZva+ma00sw/MbEDQsiozWx4Y3oxmnSfiy/KxvXQ7h44dilUJIiIxF7WwMLN44ClgKpADXG1mOQ1Wewx40Tk3CngY+GnQsnLn3JjAcHG06gyn5ib3msI1sSpBRCTmonlmMQHY5Jzb4pyrAOYDlzRYJwd4PzD+lxDLY04tokREohsW/YGdQdMFgXnBVgCXB8YvBXqYWUZgOsnMlprZIjP7l1BvYGa3BNZZGq3HMg5OG0y3hG4KCxHp1KIZFhZiXsOnsn8XOM/MPgXOA3YBNQ+QGOScyweuAR43s1OO25lzc51z+c65/KysrBYsvU6cxZGbnaun5olIpxbNsCgABgZNDwB2B6/gnNvtnLvMOTcWuD8wr7RmWeB1C/ABMDaKtZ6QL0stokSkc4tmWCwBRpjZUDNLBGYA9Vo1mVmmmdXU8H1gXmB+upl1rVkHOBtYG8VaT8iX7aOwrJDCssJYlSAiElNRCwvnnB+4A3gHWAe86pxbY2YPm1lN66bzgfVmtgHoDfw4MH8ksNTMVuDd+H7EORfTsAC1iBKRzqtLNHfunHsLeKvBvAeCxl8DXgux3cdAXjRra4q83l4pqwtXc8HQC2JcjYhI69M3uCPQu1tvMpIzdN9CRDothUUEzMzr9kMtokSkk1JYRKimjyjnGrb+FRHp+BQWEfJl+zh07BAFhwpiXYqISKtTWERI3X6ISGemsIhQblYuAKsKV8W4EhGR1qewiFB6cjr9e/TXmYWIdEoKiybQg5BEpLNSWDSBL9vH2qK1VFVXxboUEZFWpbBoAl+2j2NVx9h8YHOsSxERaVUKiybIy67r9kNEpDNRWDTByKyRGKawEJFOR2HRBCkJKZzS6xSFhYh0OgqLJlKLKBHpjBQWTeTL8rGheAPH/MdiXYqISKtRWDSRL9tHlatiffH6WJciItJqFBZNpD6iRKQzUlg00YiMESTEJbBqn/qIEpHOQ2HRRInxiZyWeZoehCQinYrCohnUIkpEOhuFRTPkZeex7eA2Dh87HOtSRERahcKiGWpucq8tWhvjSkREWofCohnUIkpEOhuFRTMMSRtCSkKKwkJEOg2FRTPEWRy5WblqESUinUbYsDCzO8wsvTWKaU/UIkpEOpNIziz6AEvM7FUzm2JmFu2i2gNfto+9n+9l/5H9sS5FRCTqwoaFc24WMAJ4FrgB2GhmPzGzU6JcW5tWc5N7TeGaGFciIhJ9Ed2zcM45YG9g8APpwGtm9mgUa2vT1CJKRDqTLuFWMLM7gZnAfuB/gX9zzlWaWRywEfhedEtsm/p270t6UrrCQkQ6hbBhAWQClznntgfPdM5Vm9lXolNW22dm+LJ9rCpUh4Ii0vFFchnqLaCkZsLMepjZRADn3LpoFdYe5GXnsbpwNd5VOhGRjiuSsHga+Dxouiwwr9PzZfsoPVbKrsO7Yl2KiEhURRIW5oL+dHbOVRPZ5asOTze5RaSziCQstpjZnWaWEBjuArZEu7D2IDc7F1BYiEjHF0lY3AqcBewCCoCJwC3RLKq96JXci349+iksRKTDC3s5yTlXCMxohVraJXX7ISKdQSTfs0gCbgZygaSa+c65m6JYV7vhy/Lx9NKnqaquIj4uPtbliIhERSSXoV7C6x/qQuCvwAAgokfEBfqSWm9mm8zs3hDLB5vZ+2a20sw+MLMBQctmmtnGwDAzsh+n9fmyfZT7y9l6cGusSxERiZpIwmK4c+4HQJlz7gXgIiAv3EZmFg88BUwFcoCrzSynwWqPAS8650YBDwM/DWzbC3gQ7/7IBODBttrzrVpEiUhnEElYVAZeD5qZD0gFhkSw3QRgk3Nui3OuApgPXNJgnRzg/cD4X4KWXwi855wrcc4dAN4DpkTwnq0uJ8vLP4WFiHRkkYTF3MBf9bOAN4G1wM8i2K4/sDNouiAwL9gK4PLA+KVADzPLiHDbNqFbYjeGpQ9TWIhIh3bCG9yBzgIPBf66/xAY1oR9h3ruRcN+Mb4LzDGzGwL734XXq20k22JmtxBoxjto0KAmlNay8rLz1EeUiHRoJwyLQGeBdwCvNmPfBcDAoOkBwO4G+98NXAZgZt2By51zpWZWAJzfYNsPQtQ3F5gLkJ+fH7MOmnzZPv648Y8c8x+ja5euja7nnONwxWGKjxRTXF5c77WkvIQ4i+OuM+6iZ9eerVi9iEh4kXTb8Z6ZfRdYgNcvFADOuZLGNwFgCTDCzIbinTHMAK4JXsHMMoGSQBci3wfmBRa9A/wk6Kb25MDyNsmX7cNf7efnH/+chLiE+kEQNF5SXoK/2n/Cfa3Yt4LfXPkb9EBCEWlLIgmLmu9T3B40zxHmkpRzzh84K3kHiAfmOefWmNnDwFLn3Jt4Zw8/NTOHdxnq9sC2JWY2Gy9wAB6OIJxiJr9fPobxg7/8AICu8V3JSMkgIzmDjJQMcrJyasdrXnsl96o3Lz05nccXPc6/vfdvPPHPJ7j7jLtj/FOJiNSxjtK9dn5+vlu6dGnM3n9n6U4cjozkDFISUpp1ZuCc47JXL+MPG/7AX2/4K2cNPCsKlYqI1DGzZc65/LDrhQsLM/taqPnOuRebWVtUxDosWsrBowcZP3c8x/zH+PSbn5LVLSvWJYlIBxZpWETSdPYLQcP/Ax4CLj6p6qRRaUlpvHbla+w/sp9rf3stVdVVsS5JRCR8WDjnvh00fAMYCyRGv7TOa2zfscyZNof3trzH7A9nx7ocEZGIziwaOgKMaOlCpL6bx97MzNEzefivD/POpndiXY6IdHKR9Dr7e+q+EBeH10VHc753IU1gZvz3Rf/NJ3s+4drfXsun3/yUgakDw28oIhIFkTSdfSxo3A9sd84VRKkeCZKSkMJrV71G/tx8rnrtKv56w19JjNcVQBFpfZFchtoB/NM591fn3EdAsZkNiWpVUuvUjFN59uJnWVSwiO+9971YlyMinVQkYfEboDpouiowT1rJlblXctfEu3jin0/wmzU69CLS+iIJiy6BLsYBCIzrWkgre/TLj3LmgDO56c2bWL9/fazLEZFOJpKwKDKz2u9VmNklwP7olSShJMYnsuCKBSR1SeKK31zBkcojsS5JRDqRSMLiVuA+M9thZjuAfwe+Gd2yJJSBqQN55bJXWFO4htv+eBsdpasWEWn7IvlS3mbn3Bl4TWZznXNnOec2Rb80CWXyKZN58LwHeXHFizz76bOxLkdEOomwYWFmPzGzNOfc5865w2aWbmY/ao3iJLRZ585i8imTueOtO/h0z6exLkdEOoFILkNNdc4drJkIPDVvWvRKknDi4+J5+dKXyeqWxRW/uYKDRw+G30hE5CREEhbxZlb7+DczSwYafxyctIqsblm8esWr7Cjdwcw3Zur+hYhEVSRh8TLwvpndbGY3A+8BL0S3LInEmQPP5LEvP8ab69/ksY8fC7+BiEgzhe3uwzn3qJmtBCYBBvwJGBztwiQyd068k7/v/Dvff//7TBwwkXMHn9uk7f3VfnYd2sW2g9tqB4BvT/w2vZJ7RaFiEWmPIukbCmAv3re4rwK2Aq9HrSJpEjPj2YufZcXeFUx/bTqffvNT+nTvU7u8sqqSgkMFbC/dXi8QaoaCQwVUufrPzDCMOUvm8OikR5k5ZiZx1pzOiUWkI2n0SXlmdiowA7gaKAYWAN91zrXJs4qO8qS85lq1bxUT/3ciOVk55Gbn1guDalfXW4th9OvRjyFpQ44bBqcOZlDqINYXr+e2P97Gxzs/5qyBZ/H0RU8zqveoGP50IhItJ/1YVTOrBv4G3FzzvQoz2+KcG9ailbaQzh4WAK+sfIXb/ngbaUlpDE4b7IVAav1AGJg6MKKea6tdNS8sf4HvLfweB8oPcOfEO3no/Ifo2bVnK/wkItJaWiIsLsU7szgL7z7FfOB/nXNDW7LQlqKw8DjnMLMW219JeQn3vX8fc5fNpU/3Pvziwl9wVe5VLfoeIhI7J/0Mbufc75xz04HTgQ+Ae4DeZva0mU1usUqlRbX0h3iv5F4885VnWPT1RfTt0ZcZr89g8suT1ZmhSCcTSXcfZc65V5xzXwEGAMuBe6NembQpE/pPYPHXFzNn6hyW7FpC3tN5zPrzLHVoKNJJNKmZi3OuxDn3P865L0arIGm74uPiuX3C7ay/Yz0zfDP48d9+TO5/5/L79b+PdWkiEmVqEylN1rt7b1689EU+mPkBKQkpXDz/Yi6Zf0ntdzREpONRWEiznTfkPJZ/czmPTnqUhVsWkvNUDj/520845j8W69JEpIU12hqqvVFrqNjaWbqTe965h9fXvc5pGafxwHkP0Kd7H7oldKNbYjdSElLqjeuLfiJtw0k3nW1vFBZtw9sb3+bbb3+bzQc2n3C9pC5JdEsIhEhit5DjQ9KGcEXOFeRl56mprkiUKCwkZo75j7GqcBWfV3zOkcojlFWUUVZZVjt+pPIIZZVl3ri//rzg9XeW7qTKVTEycyTTc6cz3Ted0zNPj/WPJ9KhKCyk3SsqK+L1da8zf/V8Ptz+IQ7H6N6ja4NjWHqb7ExApF1RWEiHsvvwbl5b+xrzV8/nHwX/ACC/Xz4zcmdwVe5VDEwdGOMKRdonhYV0WDtKd/DqmldZsGYBS3d7/+ZnDTyLGbkzuCLnCvr26HtS+6921ZSUl1BYVkhRWRGpSankZuWSEJ/QEuWLtCkKC+kUNpVsqg2OlftWYhjnDTmPGbkzuDzncjJTMnHO8XnF5xSWFYYcio4U1Zvef2T/cd22d43vyug+oxnfdzz5/fIZ33c8OVk5ChBp9xQW0umsK1rHgjULWLBmAZ/t/4x4i6dvj74UlRVxrCr0dz96du1Jdrfs2iErJeu46cKyQpbtWeYNu5dxuOIwUBcg+X3zGd9vvAJE2iWFhXRazjlW7lvJq2teZdfhXfU+/IMDIatbFkldkpq072pXzaaSTSzbvYylu5eybM8yPtnzSW2AJHVJYnTvoDOQfl6AdInznjNWWVVJWWUZn1d8TlmF9xo81CyrnQ6sU1ZZxoCeAxjTZwxj+ozhtIzTFErSIhQWIq2k2lWzsXhj7ZlHqABJSUihrKKs0TOcULrEdaF7Yne6J3YnuUsyO0p31G6fGJ+IL9vHmN5jagNkVO9RpCalRuVnlI5LYSESQ8EB8smeTzjqP0r3xO50S+hWGwDBQ7fE4+c3fEiVv9rPhuINLN+7vN5QdKSodp2haUNrw2N079GM6TOGQamD9KVGaZTCQqQTcM6x9/O9deGxbzkr9q5gQ/EGHN7/7bSkNMb0GUNedh7JXZKpqKqoG6or6k8HDZVVlcfNq3JVDEkbwsjMkZyeeTojM0cyMmskg1MHEx8XH+OjIc2hsBDpxMoqylhVuKo2RFbsW8HqwtX4q/0kxieGHBLiEhpdlhifWHuPZOuBrazbv47CssLa90vqksSpGad64VETJFkjOTXj1CbfF5LW1SbCwsymAE8A8XiPZH2kwfJBwAtAWmCde51zb5nZEGAdUPM4tkXOuVtP9F4KC5HWVVJewmf7P2Nd0TrW7feGz/Z/xtYDW2vPagxjaPrQeiFySq9TqKquOq57l+PGT7C8qrqKQamDGJY+jGHpwzgl/ZTa8f49+6ujyiaIeViYWTywAfgyUAAsAa52zq0NWmcu8Klz7mkzywHecs4NCYTFH5xzvkjfT2Eh0jaUV5azoXiDFyRBIbJ+//qwN/gNa7RjyeDeiw1je+l2thzYwo7SHfW+F5MYn8iQtCH1AqQmUIamD6V7YvdoH4J2JdKw6BLFGiYAm5xzWwIFzQcuAdYGreOAnoHxVGB3FOsRkVaQnJDM6D6jGd1ndL35VdVVbDu4jW0Ht5EYnxgyDLrGd23yzfjKqkp2HtrJlgNb2FyymS0HtrDl4Ba2HNjCxzs/pvRYab31s7tle2cgPfrjcFRVV1Hlqpr1mhifSN8efenfoz/9evSjf4/+9O9ZN967e+/aZtMtwTlHWWUZ+4/sp/hIsfdaXky3hG5ccvolLfY+oUTzzOIKYIpz7uuB6euBic65O4LW6Qu8C6QD3YBJzrllgTOLNXhnJoeAWc65v4V4j1uAWwAGDRo0fvv27VH5WUSk/TpQfoDNBwIhEjTs+XwPcRZHvMV7r3HxxFt8k16P+Y+x+/Budh/ezZ7P9+Cv9td77ziLo3e33l549OxPv+796oVJvx79SElIobi8+LgAqHltOK+iquK4nzG/Xz5LvrGkWcenLZxZhPrzoGEyXQ0875z7DzM7E3jJzHzAHmCQc67YzMYDb5hZrnPuUL2dOTcXmAveZaiW/xFEpL1LT04nPzmf/H5hPw9PSrWrprCskN2Hd7Pr0C7v9XDd69YDW/lox0cUlxeH3Ve8xdMruRcZKRlkpmQyLH0YE/pPICPZm85Iyag3npWSFdWfDaIbFgVAcFegAzj+MtPNwBQA59w/zCwJyHTOFQLHAvOXmdlm4FRANyVEpE2Kszj6dO9Dn+59GNd3XKPrHfUfZc/hPbVBUl5ZXvuhn5mSSUZyBqlJqW3uJn00w2IJMMLMhgK7gBnANQ3W2QF8CXjezEYCSUCRmWUBJc65KjMbBowAtkSxVhGRVpHUJYmh6UMZmj401qU0SdTCwjnnN7M7gHfwmsXOc86tMbOHgaXOuTeB7wC/NLN78C5R3eCcc2Z2LvCwmfmBKuBW51xJtGoVEZET05fyREQ6sUhvcLeti2IiItImKSxERCQshYWIiISlsBARkbAUFiIiEpbCQkREwlJYiIhIWAoLEREJS2EhIiJhRbNvKBEaB96ZAAAO2klEQVSRNuXoUTh40BsOH4bqam9wrm481HRj63TtCkOGeENKSmx+nh07vNdRo6L7XgoLkU7OOSgrgwMHoKSkbgierhk/eBDMID4eunQJ/9rYvC5dIDEREhK8oanjcXFw6FDdB38kQ2kpHDvxg/pOSp8+MGyYNwwdWv+1Xz/v52+q8nIvDLZtqz9s3+697tnjrTdxIixa1GI/SkgKC5EOyO+H3buhoKD+sH9/6BCorGx8XwkJ0KuXN6SmemFRVeW9h99fN97Ya6h50ZKYCOnpkJbmDenp3gd2zXRqat149+7eB3hcXP3BLPy8mumyMu9De8sWb9i6FT78EH71K+/sI7iuwYPrB0jNeHJy3Yd/w2HfvuP/LQYN8vY1dWrdWc2pp0bvmNZQWIhEUUUF7NrlvXbtevzQpRn/Aysr6wfBzp3Hj+/dW//DCrzLJFlZ3od+ejr4fHUhkJ5eN95wOiXF+3BsKc55oVFR4f0slZX1xxtOhxqvrq7/wV8znpTUcnVG6qyzjp9XUeGdEdQESPDrkiVeQIeSkOAFwZAh8NWv1o3XDH37Nu8MpSUoLESayTkoLvY+FBob9u711mtMXFxdcCQlhQ6Url29v0yLi+uCoOE+u3WDgQO9ITcXBgzwxgcMqBvS0lr2Q7+5zOouRXVUiYkwfLg3hHLwoBceW7d6l5qCwyCujTY76sD/XNIZVVV513FrTuMPH478+npjrwcPeh/827cfHwbl5fXfPynJu0wwaJB3mWDQIO9DOynJu15+7Jh3M7JmPNLh0CHvr/y8vPohUDPes2fbCAKJTFoajB3rDe2FwkLalaoq7xJMqJt927Z5H+Anuv5+svr08QIgLw8uuqguGGqGzEx9aEvHpLCQNsfvh1WrYPXq42/47dhx/A3SPn28U/gvfAGuvLL+dd60NC9gIrnpGmqZ3+9dDx882PsLvmvXVj4YIm2EwkJi7uBBr9nfxx/DRx/BP//ptTKp0bev98E/cSJMn+6N1wTCoEFeaxIRiS6FhbQq52Dz5rpg+PhjWLPGmx8XB6NHww03eC1Mxo/3QiEWLVxEpD6FhdTjnHdDNTGxZVplHD0Ky5Z5oVAzFBZ6y1JT4cwz4aqrvHCYMAF69Dj59xSRlqew6MRKS72/6lev9oaa+wT793vLu3b1LvHUDElJ9adPNO/gQfjHP7ygqKjw9jd8OEyZAmef7YVDTk7bbSYoIvUpLDqBo0fhs8/qwqBm2LGjbp3u3b32+f/yL969gMpKr1lozXD0aP3pw4e9M4RQy6qqvKDJz4e77vKC4ayzIDs7ZodARE6SwqIDqaz0viHa8Exh48a6b/MmJMDIkXDOOd43ePPyvNdBg1rur/zKyrovXolIx6D/zu2Mc1BUBOvXw4YN3mvNsHlzXbNSM++yj8/n3RPw+bxhxAgvMKIp2vsXkdansGijjh6FTZvqh0HNcPBg3XqJiV4A5ObCZZfBaad5oTByZGy6TBaRjklh0QZUV8Pf/w5vvAFr13qBsH17/f5/+vf3gmDGDO+1Zhg8OHYdi4lI56GwiKG1a+Hll+GVV7ybzUlJ3hnBGWfAzJl1gXDqqd4NaBGRWFFYtLLdu2H+fC8kPv3UOyu48EJ45BG4+GKv91ARkbZGYdEKDh+G3/7WC4g//9m77DRhAjz5pNd9hZqUikhbp7CIkspKePddLyD+7/+87x8MGwazZsG117bOk61ERFqKwqIFOQeLF3sBMX++903ojAy48Ua47jrvXoS6rxaR9khh0QIqKuDnP4fnn/eauyYlefcfrrvOux+RmBjrCkVETo7C4iT5/d5lpddegy9+Ee67z/u+Q2pqrCsTEWk5CouTUF0NN93kBcV//ifcc0+sKxIRiQ71+dlMzsG3vgUvvQSzZysoRKRjU1g0g3Pwne/A//wPfP/7cP/9sa5IRCS6FBbN8MAD8ItfwJ13wo9/rBZOItLxKSya6Kc/hR/9CL7+dXj8cQWFiHQOUQ0LM5tiZuvNbJOZ3Rti+SAz+4uZfWpmK81sWtCy7we2W29mF0azzkg98YTX2unaa+GZZxQUItJ5RK01lJnFA08BXwYKgCVm9qZzbm3QarOAV51zT5tZDvAWMCQwPgPIBfoBC83sVOdcVbTqDeeXv4S77/aaxT7/vHp6FZHOJZpnFhOATc65Lc65CmA+cEmDdRzQMzCeCuwOjF8CzHfOHXPObQU2BfYXEy+/DN/8JkybBr/+tZ4AJyKdTzTDoj+wM2i6IDAv2EPAdWZWgHdW8e0mbNsqXn8dbrgBLrjA+z6Fvo0tIp1RNMMi1BV912D6auB559wAYBrwkpnFRbgtZnaLmS01s6VFRUUnXXBDb70FV18NEyd6nQEmJ7f4W4iItAvRDIsCYGDQ9ADqLjPVuBl4FcA59w8gCciMcFucc3Odc/nOufysrKwWLB3ef9+7PzFqlBcaeviQiHRm0QyLJcAIMxtqZol4N6zfbLDODuBLAGY2Ei8sigLrzTCzrmY2FBgBLI5irfV89JHXEeCIEfDOO+rnSUQkardqnXN+M7sDeAeIB+Y559aY2cPAUufcm8B3gF+a2T14l5lucM45YI2ZvQqsBfzA7a3VEmrpUu9G9oAB8N57XhfjIiKdnXmfze1ffn6+W7p06UntY9UqOP986NkTPvwQBg4Mu4mISLtmZsucc/nh1tM3uAPWr4dJk7yb2O+/r6AQEQmmsAC2boUvfckbX7jQe/ypiIjU6fRfL9u1ywuKI0fggw/g9NNjXZGISNvT6c8sevSA3Fyv1dOoUbGuRkSkber0ZxY9e8Lvfx/rKkRE2rZOf2YhIiLhKSxERCQshYWIiISlsBARkbAUFiIiEpbCQkREwlJYiIhIWAoLEREJq8P0OmtmRcD2WNcRRiawP9ZFRKC91Antp1bV2bLaS53Q9msd7JwL+/S4DhMW7YGZLY2kK+BYay91QvupVXW2rPZSJ7SvWk9El6FERCQshYWIiISlsGhdc2NdQITaS53QfmpVnS2rvdQJ7avWRumehYiIhKUzCxERCUth0cLMbKCZ/cXM1pnZGjO7K8Q655tZqZktDwwPxKjWbWa2KlDD0hDLzcyeNLNNZrbSzMbFoMbTgo7TcjM7ZGZ3N1gnZsfTzOaZWaGZrQ6a18vM3jOzjYHX9Ea2nRlYZ6OZzYxBnT83s88C/7a/M7O0RrY94e9JK9T5kJntCvr3ndbItlPMbH3g9/XeaNZ5gloXBNW5zcyWN7Jtqx3TFuOc09CCA9AXGBcY7wFsAHIarHM+8Ic2UOs2IPMEy6cBbwMGnAH8M8b1xgN78dqFt4njCZwLjANWB817FLg3MH4v8LMQ2/UCtgRe0wPj6a1c52SgS2D8Z6HqjOT3pBXqfAj4bgS/G5uBYUAisKLh/7vWqLXB8v8AHoj1MW2pQWcWLcw5t8c590lg/DCwDugf26qa7RLgRedZBKSZWd8Y1vMlYLNzrs18+dI59yFQ0mD2JcALgfEXgH8JsemFwHvOuRLn3AHgPWBKa9bpnHvXOecPTC4CBkTr/SPVyPGMxARgk3Nui3OuApiP9+8QNSeq1cwMuAr4dTRraE0KiygysyHAWOCfIRafaWYrzOxtM8tt1cLqOOBdM1tmZreEWN4f2Bk0XUBsg28Gjf/nawvHs0Zv59we8P54ALJDrNPWju1NeGeRoYT7PWkNdwQul81r5LJeWzue/w/Y55zb2MjytnBMm0RhESVm1h14HbjbOXeoweJP8C6ljAb+C3ijtesLONs5Nw6YCtxuZuc2WG4htolJ8zkzSwQuBn4TYnFbOZ5N0ZaO7f2AH3ilkVXC/Z5E29PAKcAYYA/e5Z2G2szxDLiaE59VxPqYNpnCIgrMLAEvKF5xzv224XLn3CHn3OeB8beABDPLbOUycc7tDrwWAr/DO5UPVgAMDJoeAOxuneqOMxX4xDm3r+GCtnI8g+yruVwXeC0MsU6bOLaBG+tfAa51gYvpDUXwexJVzrl9zrkq51w18MtG3r9NHE8AM+sCXAYsaGydWB/T5lBYtLDAtcpngXXOuf9sZJ0+gfUwswl4/w7FrVclmFk3M+tRM453s3N1g9XeBL4WaBV1BlBac3klBhr9S60tHM8G3gRqWjfNBP4vxDrvAJPNLD1wWWVyYF6rMbMpwL8DFzvnjjSyTiS/J1HV4D7ZpY28/xJghJkNDZyFzsD7d4iFScBnzrmCUAvbwjFtlljfYe9oA3AO3unvSmB5YJgG3ArcGljnDmANXouNRcBZMahzWOD9VwRquT8wP7hOA57Ca2WyCsiP0TFNwfvwTw2a1yaOJ16A7QEq8f66vRnIAN4HNgZeewXWzQf+N2jbm4BNgeHGGNS5Ce86f83v6TOBdfsBb53o96SV63wp8Pu3Ei8A+jasMzA9Da/14eZo19lYrYH5z9f8bgatG7Nj2lKDvsEtIiJh6TKUiIiEpbAQEZGwFBYiIhKWwkJERMJSWIiISFgKC5ETMLMhwb2KttV9ikSbwkJERMJSWIhEyMyGmdmnZvaFBvMXBD9jwcyeN7PLA2cQfzOzTwLDWSH2eYOZzQma/oOZnR8Yn2xm/whs+5tAf2MiMaGwEImAmZ2G19/Xjc65JQ0WzwemB9ZLxOtK/S28PqG+7LwO46YDTzbh/TKBWcCkwPZLgX892Z9DpLm6xLoAkXYgC69/p8udc2tCLH8beNLMuuI9k+JD51y5maUCc8xsDFAFnNqE9zwDyAE+CnR7lQj84yR+BpGTorAQCa8Urw+ls/H68qnHOXfUzD7Ae6DRdOo6PLwH2AeMxjuLPxpi337qn+EnBV4N7+FIV7dA/SInTZehRMKrwHva3dfM7JpG1pkP3Ij30Jua3mNTgT3O61r7erxHfza0DRhjZnFmNpC6rqoXAWeb2XAAM0sxs6acmYi0KIWFSAScc2V4z324x8xCPa7zXbxnMi903mM9Af4bmGlmi/AuQZWF2O4jYCter6qP4T3ICedcEXAD8GszW4kXHqe32A8k0kTqdVZERMLSmYWIiISlsBARkbAUFiIiEpbCQkREwlJYiIhIWAoLEREJS2EhIiJhKSxERCSs/w/9UxTnQqsgRAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = range(1, 20)\n",
    "%matplotlib inline\n",
    "plt.plot(x_axis, training_score_list, label = 'Train Score', c = 'g')\n",
    "plt.plot(x_axis, testing_score_list, label = 'Test Score', c = 'b')\n",
    "plt.xlabel('k value')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=17, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 17)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('LSVM', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
       "     verbose=0)), ('Dec Tree', DecisionTreeClassifier(class_weight=None, criterion=...wski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=17, p=2,\n",
       "           weights='uniform'))],\n",
       "         flatten_transform=None, n_jobs=1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC 0.8441223436924211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier 0.8422798182041519\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=17, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier 0.8331900257953568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('LSVM', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
       "     verbose=0)), ('Dec Tree', DecisionTreeClassifier(class_weight=None, criterion=...wski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=17, p=2,\n",
       "           weights='uniform'))],\n",
       "         flatten_transform=None, n_jobs=1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier 0.8478073946689596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srohi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "vote_cls = VotingClassifier(estimators = [('LSVM', linear_svm), ('Dec Tree', dec_tree), ('KNN', knn)])\n",
    "vote_cls.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (linear_svm, dec_tree, knn, vote_cls):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2\n",
    "First train the following models on X_train and y_train. \n",
    "- Support vector machine with kernel 'rbf' and default parameters. \n",
    "- Decision tree with ``max_depth = 3``\n",
    "- Logistic regression with default parameters.\n",
    "\n",
    "In the all above models, set ``random_sate = 0``.\n",
    "Compute the test recall score of soft-voting classifier? (two significant digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Support Vector Machine with rbf kernel trick\n",
    "from sklearn.svm import SVC\n",
    "rbf_class = SVC(random_state = 0)\n",
    "rbf_class.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logisitic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model = LogisticRegression(random_state = 0)\n",
    "log_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-87-11cae3333c22>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-87-11cae3333c22>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    probas = [vote_cls_soft.fit(X_train, y_train).predict_proba(X_train) for c in (rbf_class, dec_tree, log_model, vote_cls_soft), probabilities = True]\u001b[0m\n\u001b[1;37m                                                                                                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "vote_cls_soft = VotingClassifier(estimators = [('SVM with kernel RBF', rbf_class), ('Dec Tree', dec_tree), ('Logistic', log_model)], voting = 'soft')\n",
    "vote_cls_soft.fit(X_train, y_train)\n",
    "#probas = [vote_cls_soft.fit(X_train, y_train).predict_proba(X_train) for c in (rbf_class, dec_tree, log_model, vote_cls_soft)]\n",
    "#print(probas)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (rbf_class, dec_tree, log_model, vote_cls_soft):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3\n",
    "Train a bagging classifier on base model logistic regression with default parameters. Set the hyper-parameter as follow: \n",
    "```Python\n",
    "n_estimators = 100\n",
    "max_samples = 500\n",
    "max_features = 5\n",
    "random_state = 0```\n",
    "What is out of bag score? (two significant digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=5,\n",
       "         max_samples=500, n_estimators=100, n_jobs=1, oob_score=False,\n",
       "         random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "log_model_2 = LogisticRegression()\n",
    "bag_clf = BaggingClassifier(log_model_2, n_estimators = 100, max_samples = 500,\n",
    "                           max_features = 5, random_state = 0)\n",
    "\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7578921508414199\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=5,\n",
       "         max_samples=500, n_estimators=100, n_jobs=1, oob_score=False,\n",
       "         random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.76\n",
      "Test score: 0.76\n"
     ]
    }
   ],
   "source": [
    "bag_clf.fit(X_train, y_train)\n",
    "print('Train score: {:.2f}'.format(bag_clf.score(X_train, y_train)))\n",
    "print('Test score: {:.2f}'.format(bag_clf.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4\n",
    "Use a grid search to find the best parameters of a random forest machine learning model on this dataset. \n",
    "```Python \n",
    "max_depth in [1, 3, 5, 7]\n",
    "max_features in [5, 7, 9]\n",
    "n_estimators in [100, 200, 500]\n",
    "random_state = 0\n",
    "cv = 5```\n",
    "\n",
    "What are the best parameters of the model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [1, 3, 5, 7], 'max_features': [5, 7, 9], 'n_estimators': [100, 200, 500]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 7, 'max_features': 9, 'n_estimators': 100}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfor_clf = RandomForestClassifier(n_jobs = -1, random_state = 0)\n",
    "\n",
    "#Grid Search\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "param_grid = {\n",
    "    'max_depth': [1, 3, 5, 7],\n",
    "    'max_features': [5, 7, 9],\n",
    "    'n_estimators': [100, 200, 500]    \n",
    "}\n",
    "\n",
    "CV_rfor = GridSearchCV(estimator = rfor_clf, param_grid = param_grid, cv = 5)\n",
    "CV_rfor.fit(X_train, y_train)\n",
    "CV_rfor.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5\n",
    "Train a random forest machine learning model on this dataset using the best parameters in the previous question. \n",
    "\n",
    "Which feature has the highest importance? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=7, max_features=9, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfor_clf_upt = RandomForestClassifier(n_jobs = -1, max_depth = 7, max_features = 9, n_estimators = 100, random_state = 0)\n",
    "rfor_clf_upt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-d0a97f3286d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Feature Importance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m feature_importance = pd.DataFrame(rfor_clf_upt.feature_importances_,\n\u001b[1;32m----> 3\u001b[1;33m                                  \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m                                  columns = ['importances']).sort_values('importance', ascending = False)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "#Feature Importance\n",
    "feature_importance = pd.DataFrame(rfor_clf_upt.feature_importances_,\n",
    "                                 index = X_train.columns,\n",
    "                                 columns = ['importances']).sort_values('importance', ascending = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
