{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> Project 2\n",
    "\n",
    "Project Description:\n",
    "- Use same datasets as Project 1.\n",
    "- Preprocess data: Explore data and apply data scaling.\n",
    "\n",
    "Regression Task:\n",
    "- Apply any two models with bagging and any two models with pasting.\n",
    "- Apply any two models with adaboost boosting\n",
    "- Apply one model with gradient boosting\n",
    "- Apply PCA on data and then apply all the models in project 1 again on data you get from PCA. Compare your results with results in project 2. You don't need to apply all the models twice. Just copy the result table from project 1, prepare similar table for all the models after PCA and compare both tables. Does PCA help in getting better results?\n",
    "- Apply deep learning models covered in class\n",
    "\n",
    "Classification Task:\n",
    "- Apply two voting classifiers - one with hard voting and one with soft voting\n",
    "- Apply any two models with bagging and any two models with pasting.\n",
    "- Apply any two models with adaboost boosting\n",
    "- Apply one model with gradient boosting\n",
    "- Apply PCA on data and then apply all the models in project 1 again on data you get from PCA. Compare your results with results in project 1. You don't need to apply all the models twice. Just copy the result table from project 1, prepare similar table for all the models after PCA and compare both tables. Does PCA help in getting better results?\n",
    "- Apply deep learning models covered in class\n",
    "\n",
    "Deliverables:\n",
    "- Use markdown to provide inline comments for this project.\n",
    "- Your outputs should be clearly executed in the notebook i.e. we should not need to rerun the code to obtain the outputs.\n",
    "- Visualization encouraged.\n",
    "- If you are submitting two different files, then please only one group member submit both the files. If you submit two files separately from different accounts, it will be submitted as two different attempts.\n",
    "- If you are submitting two different files, then please follow below naming convetion:\n",
    "    Project2_Regression_GroupXX_Firstname1_Firstname2.ipynb\n",
    "    Project2_Classification_GroupXX_Firstname1_Firstname2.ipynb\n",
    "- If you are submitting single file, then please follow below naming convetion:\n",
    "    Project2_Both_GroupXX_Firstname1_Firstname2.ipynb\n",
    "\n",
    "Questions regarding the project:\n",
    "- We have created a discussion board under Projects folder on e-learning. Create threads over there and post your queries related to project there.\n",
    "- We will also answer queries there. We will not be answering any project related queries through the mail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "audit_risk = pd.read_csv('audit_risk.csv')\n",
    "trial = pd.read_csv('trial.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(audit_risk, trial, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sector_score</th>\n",
       "      <th>LOCATION_ID</th>\n",
       "      <th>PARA_A</th>\n",
       "      <th>Score_A</th>\n",
       "      <th>Risk_A</th>\n",
       "      <th>PARA_B</th>\n",
       "      <th>Score_B</th>\n",
       "      <th>Risk_B</th>\n",
       "      <th>TOTAL</th>\n",
       "      <th>numbers</th>\n",
       "      <th>...</th>\n",
       "      <th>Audit_Risk</th>\n",
       "      <th>Risk</th>\n",
       "      <th>SCORE_A</th>\n",
       "      <th>SCORE_B</th>\n",
       "      <th>Marks</th>\n",
       "      <th>MONEY_Marks</th>\n",
       "      <th>District</th>\n",
       "      <th>Loss</th>\n",
       "      <th>LOSS_SCORE</th>\n",
       "      <th>History_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.89</td>\n",
       "      <td>23</td>\n",
       "      <td>4.18</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.508</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.500</td>\n",
       "      <td>6.68</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7148</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.89</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.83</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.966</td>\n",
       "      <td>4.83</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5108</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.89</td>\n",
       "      <td>6</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.74</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3096</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.89</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.80</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.480</td>\n",
       "      <td>10.80</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.5060</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.89</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2832</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sector_score LOCATION_ID  PARA_A  Score_A  Risk_A  PARA_B  Score_B  Risk_B  \\\n",
       "0          3.89          23    4.18      0.6   2.508    2.50      0.2   0.500   \n",
       "1          3.89           6    0.00      0.2   0.000    4.83      0.2   0.966   \n",
       "2          3.89           6    0.51      0.2   0.102    0.23      0.2   0.046   \n",
       "3          3.89           6    0.00      0.2   0.000   10.80      0.6   6.480   \n",
       "4          3.89           6    0.00      0.2   0.000    0.08      0.2   0.016   \n",
       "\n",
       "   TOTAL  numbers      ...        Audit_Risk  Risk  SCORE_A  SCORE_B  Marks  \\\n",
       "0   6.68      5.0      ...            1.7148     1      6.0      2.0    2.0   \n",
       "1   4.83      5.0      ...            0.5108     0      2.0      2.0    2.0   \n",
       "2   0.74      5.0      ...            0.3096     0      2.0      2.0    2.0   \n",
       "3  10.80      6.0      ...            3.5060     1      2.0      6.0    6.0   \n",
       "4   0.08      5.0      ...            0.2832     0      2.0      2.0    2.0   \n",
       "\n",
       "   MONEY_Marks  District  Loss  LOSS_SCORE  History_score  \n",
       "0          2.0       2.0   0.0         2.0            2.0  \n",
       "1          2.0       2.0   0.0         2.0            2.0  \n",
       "2          2.0       2.0   0.0         2.0            2.0  \n",
       "3          6.0       2.0   0.0         2.0            2.0  \n",
       "4          2.0       2.0   0.0         2.0            2.0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(810, 35)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sector_score      float64\n",
       "LOCATION_ID        object\n",
       "PARA_A            float64\n",
       "Score_A           float64\n",
       "Risk_A            float64\n",
       "PARA_B            float64\n",
       "Score_B           float64\n",
       "Risk_B            float64\n",
       "TOTAL             float64\n",
       "numbers           float64\n",
       "Score_B.1         float64\n",
       "Risk_C            float64\n",
       "Money_Value       float64\n",
       "Score_MV          float64\n",
       "Risk_D            float64\n",
       "District_Loss       int64\n",
       "PROB              float64\n",
       "RiSk_E            float64\n",
       "History             int64\n",
       "Prob              float64\n",
       "Risk_F            float64\n",
       "Score             float64\n",
       "Inherent_Risk     float64\n",
       "CONTROL_RISK      float64\n",
       "Detection_Risk    float64\n",
       "Audit_Risk        float64\n",
       "Risk                int64\n",
       "SCORE_A           float64\n",
       "SCORE_B           float64\n",
       "Marks             float64\n",
       "MONEY_Marks       float64\n",
       "District          float64\n",
       "Loss              float64\n",
       "LOSS_SCORE        float64\n",
       "History_score     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.LOCATION_ID.apply(lambda x: x.isnumeric())]\n",
    "df.LOCATION_ID = df.LOCATION_ID.apply(eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Score_A', 'Score_B'], axis=1, inplace = True)\n",
    "df.dropna(axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(625, 33)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Targets and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1.714800\n",
       "1       0.510800\n",
       "2       0.309600\n",
       "3       3.506000\n",
       "4       0.283200\n",
       "5       0.431200\n",
       "6       6.354800\n",
       "7       3.606800\n",
       "8       3.441200\n",
       "10      2.400800\n",
       "11     21.422400\n",
       "12      5.756800\n",
       "14      0.313880\n",
       "15      1.876800\n",
       "16     20.268000\n",
       "17      2.898400\n",
       "19     14.298400\n",
       "20     13.824000\n",
       "22     56.709600\n",
       "23      0.322000\n",
       "24      9.263200\n",
       "25      1.310000\n",
       "26      0.324280\n",
       "27      4.971600\n",
       "28      0.321200\n",
       "30      2.610000\n",
       "31     18.571200\n",
       "32      0.393600\n",
       "33      0.512400\n",
       "34      0.297200\n",
       "         ...    \n",
       "772     0.280000\n",
       "774     0.284000\n",
       "775     2.423600\n",
       "776     0.290068\n",
       "777     0.292460\n",
       "778     0.280000\n",
       "779     0.313600\n",
       "782     0.315200\n",
       "783     0.283600\n",
       "784     0.332000\n",
       "786     0.280000\n",
       "788     0.321600\n",
       "789     0.339600\n",
       "791     0.280000\n",
       "792     0.280000\n",
       "793     0.280000\n",
       "794     0.280000\n",
       "795     0.303600\n",
       "796     0.280800\n",
       "799     0.334800\n",
       "800     0.324400\n",
       "801     0.318800\n",
       "802     0.324000\n",
       "803     0.328000\n",
       "804     0.315600\n",
       "805     0.315600\n",
       "806     0.313600\n",
       "807     0.291200\n",
       "808     0.288000\n",
       "809     0.292800\n",
       "Name: Audit_Risk, Length: 625, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['Audit_Risk', 'Risk'], axis = 1)\n",
    "y = df['Audit_Risk']\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the Dataset into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_orig, X_test_orig, y_train, y_test = train_test_split(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train_orig)\n",
    "X_test = scaler.transform(X_test_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,\n",
       "     intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
       "     random_state=None, tol=0.0001, verbose=0),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 100}\n",
      "Best cross-validation score: 0.64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVR\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "grid_search = GridSearchCV(LinearSVR(), param_grid, cv=5, return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 - Bagging and Pasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithm 1 - Linear SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(base_estimator=LinearSVR(C=100, dual=True, epsilon=0.0, fit_intercept=True,\n",
       "     intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
       "     random_state=0, tol=0.0001, verbose=0),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=10, n_jobs=-1, oob_score=False,\n",
       "         random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([  2.36880441,   2.34564693,   2.21342809,  23.61056949,\n",
       "         0.31318199,   0.37417211,   0.30773731,   0.32862345,\n",
       "         0.26712637,   5.85271798,   0.26712637,   0.26696716,\n",
       "        26.56279965,   3.0450498 ,   0.26468528,   0.29932744,\n",
       "        27.54773181,   0.42327818,   0.27269384,   0.32261098,\n",
       "        22.90701735,   3.01110413,   0.26684776,   0.26026442,\n",
       "         0.49936011,   0.26696716,  21.83040404,   2.39690184,\n",
       "         0.35140498,   3.25791521,   5.12268632,   0.28810491,\n",
       "         1.24230463,   0.31994325,  20.4949686 ,   4.9113832 ,\n",
       "         0.34432843,  33.28996042,   6.64874022,  12.7179494 ,\n",
       "         0.26026442,   0.33964477,   0.28468322,   1.43193382,\n",
       "         2.39733391,   5.95572227,   0.31833224,   0.26749827,\n",
       "         1.71707656,  23.7835994 ,   1.53139078,   0.30988369,\n",
       "         0.3077694 ,   1.54370097,   1.54718186,   0.69270522,\n",
       "        42.90927673,   2.22199443,   0.37737424,   1.51274446,\n",
       "         4.95408445,  30.07347917,   0.26903125,   0.28273583,\n",
       "         0.27686137,  26.64477179,   3.38879185,   0.30258166,\n",
       "         2.85091818,   1.37211698,   0.28338324,   1.68956845,\n",
       "        13.20220824,  27.49698645,   7.36507774,   9.32186024,\n",
       "         0.33895004,   0.33758058,   0.2762199 ,   0.6056468 ,\n",
       "         2.34225635,   2.5107925 ,   0.2675244 , 115.3282515 ,\n",
       "         0.26696716,  11.10941524,  12.70821361,   0.34361816,\n",
       "         0.35208786,   0.27751745,  17.96041992,   0.33966493,\n",
       "         0.44943875,   0.32526344,   0.45854017,   0.26724578,\n",
       "         2.38477751,   4.01626056,  11.23019472,   4.57848273,\n",
       "         1.47232877,   0.26696716,  23.04374556,  10.88029563,\n",
       "         0.32103235,   3.27263852,  66.31170148,   0.28147212,\n",
       "        10.51838997,   1.26578214,   0.30673736,   0.59601597,\n",
       "         2.6891596 ,   0.28048709,  15.47680325,   2.96317576,\n",
       "         2.35909529,   0.26712637,   2.5588287 ,   6.42304606,\n",
       "         0.26696716,   1.39924915,   0.33131467,  46.27042627,\n",
       "        27.30984439,   2.32395941,   0.26036233,   7.03516582,\n",
       "         0.28727019,   0.26684776,   0.26724578,   0.31602749,\n",
       "        15.31769822,   1.62989439,   2.31700622,   5.28541693,\n",
       "         0.32080975,   0.34090333,   0.27148012,   2.49456491,\n",
       "         0.3278334 ,   1.56151869,   0.33005034,   0.32103235,\n",
       "         0.26780301,   6.15819115,   2.32395941,   3.90675175,\n",
       "         0.32731407,   0.35097358,   1.52214785,   0.26276743,\n",
       "         1.14386979,   0.2650256 ,   2.23568587,   0.34840899,\n",
       "         0.26033833])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BAGGING\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "bagging_reg_1a = BaggingRegressor(LinearSVR(C = 100, random_state = 0), bootstrap = True, n_jobs = -1, random_state = 0)\n",
    "\n",
    "bagging_reg_1a.fit(X_train, y_train)\n",
    "LinSVR1a = bagging_reg_1a.predict(X_test)\n",
    "LinSVR1a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining the Accuracy of Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Training Score for Linear Support Vector Regressor: 0.41\n",
      "Bagging Testing Score for Linear Support Vector Regressor: 0.69\n"
     ]
    }
   ],
   "source": [
    "print('Bagging Training Score for Linear Support Vector Regressor: {:.2f}'.format(bagging_reg_1a.score(X_train, y_train)))\n",
    "print('Bagging Testing Score for Linear Support Vector Regressor: {:.2f}'.format(bagging_reg_1a.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(base_estimator=LinearSVR(C=100, dual=True, epsilon=0.0, fit_intercept=True,\n",
       "     intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
       "     random_state=0, tol=0.0001, verbose=0),\n",
       "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=10, n_jobs=-1, oob_score=False,\n",
       "         random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([  2.36880441,   2.34564693,   2.21342809,  23.61056949,\n",
       "         0.31318199,   0.37417211,   0.30773731,   0.32862345,\n",
       "         0.26712637,   5.85271798,   0.26712637,   0.26696716,\n",
       "        26.56279965,   3.0450498 ,   0.26468528,   0.29932744,\n",
       "        27.54773181,   0.42327818,   0.27269384,   0.32261098,\n",
       "        22.90701735,   3.01110413,   0.26684776,   0.26026442,\n",
       "         0.49936011,   0.26696716,  21.83040404,   2.39690184,\n",
       "         0.35140498,   3.25791521,   5.12268632,   0.28810491,\n",
       "         1.24230463,   0.31994325,  20.4949686 ,   4.9113832 ,\n",
       "         0.34432843,  33.28996042,   6.64874022,  12.7179494 ,\n",
       "         0.26026442,   0.33964477,   0.28468322,   1.43193382,\n",
       "         2.39733391,   5.95572227,   0.31833224,   0.26749827,\n",
       "         1.71707656,  23.7835994 ,   1.53139078,   0.30988369,\n",
       "         0.3077694 ,   1.54370097,   1.54718186,   0.69270522,\n",
       "        42.90927673,   2.22199443,   0.37737424,   1.51274446,\n",
       "         4.95408445,  30.07347917,   0.26903125,   0.28273583,\n",
       "         0.27686137,  26.64477179,   3.38879185,   0.30258166,\n",
       "         2.85091818,   1.37211698,   0.28338324,   1.68956845,\n",
       "        13.20220824,  27.49698645,   7.36507774,   9.32186024,\n",
       "         0.33895004,   0.33758058,   0.2762199 ,   0.6056468 ,\n",
       "         2.34225635,   2.5107925 ,   0.2675244 , 115.3282515 ,\n",
       "         0.26696716,  11.10941524,  12.70821361,   0.34361816,\n",
       "         0.35208786,   0.27751745,  17.96041992,   0.33966493,\n",
       "         0.44943875,   0.32526344,   0.45854017,   0.26724578,\n",
       "         2.38477751,   4.01626056,  11.23019472,   4.57848273,\n",
       "         1.47232877,   0.26696716,  23.04374556,  10.88029563,\n",
       "         0.32103235,   3.27263852,  66.31170148,   0.28147212,\n",
       "        10.51838997,   1.26578214,   0.30673736,   0.59601597,\n",
       "         2.6891596 ,   0.28048709,  15.47680325,   2.96317576,\n",
       "         2.35909529,   0.26712637,   2.5588287 ,   6.42304606,\n",
       "         0.26696716,   1.39924915,   0.33131467,  46.27042627,\n",
       "        27.30984439,   2.32395941,   0.26036233,   7.03516582,\n",
       "         0.28727019,   0.26684776,   0.26724578,   0.31602749,\n",
       "        15.31769822,   1.62989439,   2.31700622,   5.28541693,\n",
       "         0.32080975,   0.34090333,   0.27148012,   2.49456491,\n",
       "         0.3278334 ,   1.56151869,   0.33005034,   0.32103235,\n",
       "         0.26780301,   6.15819115,   2.32395941,   3.90675175,\n",
       "         0.32731407,   0.35097358,   1.52214785,   0.26276743,\n",
       "         1.14386979,   0.2650256 ,   2.23568587,   0.34840899,\n",
       "         0.26033833])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PASTING\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "pasting_reg_1b = BaggingRegressor(LinearSVR(C = 100, random_state = 0), bootstrap = False, n_jobs = -1, random_state = 0)\n",
    "\n",
    "pasting_reg_1b.fit(X_train, y_train)\n",
    "LinSVR_1b = pasting_reg_1b.predict(X_test)\n",
    "LinSVR_1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasting Training Score for Linear Support Vector Regressor: 0.41\n",
      "Pasting Testing Score for Linear Support Vector Regressor: 0.69\n"
     ]
    }
   ],
   "source": [
    "print('Pasting Training Score for Linear Support Vector Regressor: {:.2f}'.format(pasting_reg_1b.score(X_train, y_train)))\n",
    "print('Pasting Testing Score for Linear Support Vector Regressor: {:.2f}'.format(pasting_reg_1b.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithm 2 - RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(base_estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=20,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([  1.3079757 ,   1.3079757 ,   3.44039167,  31.26032645,\n",
       "         0.37045163,   0.37045163,   0.37045163,   0.37045163,\n",
       "         0.37045163,   6.4276841 ,   0.37045163,   0.37045163,\n",
       "        31.5745179 ,   1.77040472,   0.37045163,   0.37045163,\n",
       "        36.75450362,   0.37045163,   0.37045163,   0.37045163,\n",
       "        28.02597588,   4.08901972,   0.37045163,   0.37045163,\n",
       "         0.38409643,   0.37045163,  21.36731034,   1.64198828,\n",
       "         0.37045163,   3.92537986,   7.71762853,   0.37045163,\n",
       "         1.69563928,   0.37045163,  15.89739348,   5.04354486,\n",
       "         0.37045163,  39.67899409,   7.17163379,  14.30161988,\n",
       "         0.37045163,   0.37045163,   0.37045163,   1.48136812,\n",
       "         1.60639217,   9.12084166,   0.37045163,   0.37045163,\n",
       "         2.64596447,  19.98224439,   2.40064634,   0.37045163,\n",
       "         0.37045163,   2.83241997,   1.74945325,   0.44652187,\n",
       "        53.18219638,   3.43091033,   0.37045163,   2.52469386,\n",
       "         8.00092302,  42.66569946,   0.37045163,   0.37045163,\n",
       "         0.37045163,  41.8919576 ,   4.24288997,   0.37045163,\n",
       "         2.98139882,   1.54424682,   0.37045163,   2.14657483,\n",
       "        14.82007179,  35.14827664,   7.84443563,  10.75345237,\n",
       "         0.37045163,   0.37045163,   0.37045163,   0.42293665,\n",
       "         1.3079757 ,   3.47227694,   0.37045163, 132.35421217,\n",
       "         0.37045163,  13.05752352,  31.20843327,   0.37045163,\n",
       "         0.37045163,   0.37045163,  17.21258843,   0.37045163,\n",
       "         0.37045163,   0.37045163,   0.37045163,   0.37045163,\n",
       "         3.36336594,   4.68916259,  13.72098104,   5.05087042,\n",
       "         1.58544069,   0.37045163,  17.61526231,  18.16263327,\n",
       "         0.37045163,   4.36124381, 108.63727857,   0.37045163,\n",
       "        11.00943294,   1.69563928,   0.37045163,   0.42293665,\n",
       "         1.77040472,   0.37045163,   6.90211561,   3.88894005,\n",
       "         1.3079757 ,   0.37045163,   3.52380263,   6.6770162 ,\n",
       "         0.37045163,   2.05212386,   0.37045163,  30.46528095,\n",
       "        20.18310169,   1.3079757 ,   0.37045163,   8.28698999,\n",
       "         0.37045163,   0.37045163,   0.37045163,   0.37045163,\n",
       "         3.39918751,   2.7392686 ,   1.3079757 ,   5.52776762,\n",
       "         0.37045163,   0.37045163,   0.37045163,   1.71554767,\n",
       "         0.37045163,   2.3714854 ,   0.37045163,   0.37045163,\n",
       "         0.37045163,   6.35875995,   1.3079757 ,   4.53940166,\n",
       "         0.37045163,   0.37045163,   2.87063535,   0.37045163,\n",
       "         1.63812089,   0.37045163,   1.91408119,   0.37045163,\n",
       "         0.37045163])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg_1c = RandomForestRegressor(max_leaf_nodes = 20, random_state = 0)\n",
    "bagging_reg_1c = BaggingRegressor(forest_reg_1c, n_estimators = 10, bootstrap = True)\n",
    "\n",
    "bagging_reg_1c.fit(X_train, y_train)\n",
    "y_predict_1c = bagging_reg_1c.predict(X_test)\n",
    "y_predict_1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Training Score for Linear Support Vector Regressor: 0.72\n",
      "Bagging Testing Score for Linear Support Vector Regressor: 0.85\n"
     ]
    }
   ],
   "source": [
    "print('Bagging Training Score for Linear Support Vector Regressor: {:.2f}'.format(bagging_reg_1c.score(X_train, y_train)))\n",
    "print('Bagging Testing Score for Linear Support Vector Regressor: {:.2f}'.format(bagging_reg_1c.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(base_estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=20,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False),\n",
       "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=10, n_jobs=-1, oob_score=False,\n",
       "         random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([  1.28755338,   1.28755338,   3.10814439,  45.02350219,\n",
       "         0.42356702,   0.42356702,   0.42356702,   0.42356702,\n",
       "         0.42356702,   6.37921711,   0.42356702,   0.42356702,\n",
       "        30.11298633,   1.76020548,   0.42356702,   0.42356702,\n",
       "        35.46610511,   0.42356702,   0.42356702,   0.42356702,\n",
       "        21.77903346,   4.50683913,   0.42356702,   0.42356702,\n",
       "         0.42356702,   0.42356702,  20.31819093,   1.69228576,\n",
       "         0.42356702,   3.34705692,   7.56392073,   0.42356702,\n",
       "         1.69823473,   0.42356702,  14.91708895,   5.38643317,\n",
       "         0.42356702,  42.21609006,   6.65363606,  14.19499376,\n",
       "         0.42356702,   0.42356702,   0.42356702,   1.51650792,\n",
       "         1.67058408,   9.69804476,   0.42356702,   0.42356702,\n",
       "         2.5779739 ,  17.24897203,   2.47052396,   0.42356702,\n",
       "         0.42356702,   2.61690781,   1.76020548,   0.48412972,\n",
       "        56.31173055,   2.96176054,   0.42356702,   2.48189592,\n",
       "         8.91266605,  47.7977605 ,   0.42356702,   0.42356702,\n",
       "         0.42356702,  47.49630245,   4.51034719,   0.42356702,\n",
       "         2.88043046,   1.51434462,   0.42356702,   2.18432375,\n",
       "        14.22859259,  34.78171507,   7.64859247,   9.02345936,\n",
       "         0.42356702,   0.42356702,   0.42356702,   0.4385101 ,\n",
       "         1.28755338,   3.22804717,   0.42356702,  96.7941256 ,\n",
       "         0.42356702,  12.21204874,  32.61241473,   0.42356702,\n",
       "         0.42356702,   0.42356702,  17.12728482,   0.42356702,\n",
       "         0.42356702,   0.42356702,   0.42356702,   0.42356702,\n",
       "         3.08166332,   4.9049726 ,  12.84200593,   5.47735211,\n",
       "         1.67058408,   0.42356702,  16.79243793,  18.08579552,\n",
       "         0.42356702,   4.45273161, 104.97937538,   0.42356702,\n",
       "        10.4772315 ,   1.69823473,   0.42356702,   0.4385101 ,\n",
       "         1.76020548,   0.42356702,   3.2755584 ,   3.95929221,\n",
       "         1.28755338,   0.42356702,   3.05781714,   6.53349255,\n",
       "         0.42356702,   2.15336818,   0.42356702,  30.53837199,\n",
       "        20.89079011,   1.28755338,   0.42356702,   7.8733797 ,\n",
       "         0.42356702,   0.42356702,   0.42356702,   0.42356702,\n",
       "         2.32984108,   2.53727949,   1.28755338,   5.39835735,\n",
       "         0.42356702,   0.42356702,   0.42356702,   1.71258062,\n",
       "         0.42356702,   2.47052396,   0.42356702,   0.42356702,\n",
       "         0.42356702,   6.32565643,   1.28755338,   4.89073581,\n",
       "         0.42356702,   0.42356702,   2.28663384,   0.42356702,\n",
       "         1.69823473,   0.42356702,   1.87830109,   0.42356702,\n",
       "         0.42356702])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg_1d = RandomForestRegressor(max_leaf_nodes = 20, random_state = 0)\n",
    "pasting_reg_1d = BaggingRegressor(forest_reg_1d, n_estimators = 10, bootstrap = False, n_jobs = -1, random_state = 0)\n",
    "\n",
    "#Fitting the Bagging Regressor\n",
    "pasting_reg_1d.fit(X_train, y_train)\n",
    "y_predict_1d = pasting_reg_1d.predict(X_test)\n",
    "y_predict_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasting Training Score for Linear Support Vector Regressor: 0.91\n",
      "Pasting Testing Score for Linear Support Vector Regressor: 0.83\n"
     ]
    }
   ],
   "source": [
    "print('Pasting Training Score for RandomForest Regressor: {:.2f}'.format(pasting_reg_1d.score(X_train, y_train)))\n",
    "print('Pasting Testing Score for RandomForest Regressor: {:.2f}'.format(pasting_reg_1d.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 - AdaBoosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 1 - Linear Support Vector Machine - Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVR uses only a subset of training data - any data near the prediction of the model\n",
    "\n",
    "Uses decision boundaries and a hyperplane in regression of data. Linear SVR performs faster and allows for more manipulation of options than SVR with linear kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,\n",
       "     intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
       "     random_state=0, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "#Stock Model without AdaBoosting\n",
    "svm_reg_2a_stock = LinearSVR(random_state = 0)\n",
    "svm_reg_2a_stock.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Characteristics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Regression Coefficients:  [-3.82080720e-03 -3.51550345e-04  3.93959409e+00  4.19351414e+00\n",
      "  2.79476349e+00  2.79460203e+00  3.04923695e+00  1.04761882e+00\n",
      "  1.19047530e+00  1.10389562e+00  6.01807800e+00  3.38095059e+00\n",
      "  6.02051369e+00  1.82115657e-01  1.19047530e+00  7.49036382e-01\n",
      "  2.35245470e+00  7.05615771e+00  2.26427134e+00  2.03230089e+00\n",
      "  6.89032067e+00  2.54169222e+00  0.00000000e+00 -3.66859691e-03\n",
      "  6.90475297e-01  1.19047530e+00  3.38095059e+00  1.82115657e-01\n",
      "  6.90475297e-01  1.19047530e+00  7.05615771e+00]\n",
      "Support Vector Regression Intercept: [0.28295961]\n"
     ]
    }
   ],
   "source": [
    "#Regression Equation Coefficient\n",
    "print('Support Vector Regression Coefficients: ', svm_reg_2a_stock.coef_)\n",
    "#Regression Equation Intercept\n",
    "print('Support Vector Regression Intercept:',svm_reg_2a_stock.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearSVR AdaBoosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fits a regressor on the original dataset, and creates copies of the regressor where weights are adjusted based on the erros of prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying AdaBoosting to LinearSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,\n",
       "     intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
       "     random_state=0, tol=0.0001, verbose=0),\n",
       "         learning_rate=1.0, loss='linear', n_estimators=50, random_state=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "#Updated Model after AdaBoosting\n",
    "svm_reg_2a_upt = LinearSVR(random_state = 0)\n",
    "\n",
    "adaBoost_2a = AdaBoostRegressor(svm_reg_2a_upt, random_state = 0)\n",
    "adaBoost_2a.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the Decision Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Support Vector Regression AdaBoost Training Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Training Accuracy Score: 0.72\n"
     ]
    }
   ],
   "source": [
    "print('AdaBoost Training Accuracy Score: {:.2f}'.format(adaBoost_2a.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear SVR AdaBoost Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.03556971e+01,  3.03589338e+01,  8.56950381e+00,  2.41676802e+01,\n",
       "        2.86145124e-01, -4.36617808e-01,  8.15059090e-02,  3.11963937e-01,\n",
       "        2.45056920e-01,  8.25393352e+00,  2.45056920e-01,  2.81008050e-01,\n",
       "        7.06874044e+01,  3.48915621e+01, -1.55694418e+00,  2.95430223e-01,\n",
       "        7.83103320e+01, -3.62686106e-01,  2.89929693e-01,  3.01088007e-01,\n",
       "        4.55781580e+01,  6.53060460e+00,  2.81168600e-01, -1.26531388e+00,\n",
       "        3.08576342e-01,  2.81008050e-01,  3.49537623e+01,  2.77116554e+01,\n",
       "        3.34150885e-02,  1.79394625e+01,  1.39317079e+01, -1.04881454e+00,\n",
       "        1.89402897e+00,  3.15223274e-01,  4.88289403e+01,  9.76835812e+00,\n",
       "        4.29971928e-02,  6.84077690e+01,  9.74133705e+00,  1.31940081e+01,\n",
       "       -1.26531388e+00, -9.67603803e-01, -3.60774704e-02,  1.77368179e+01,\n",
       "        2.83428498e+01,  1.57171051e+01, -5.21161642e+00,  2.81246422e-01,\n",
       "        2.18155915e+00,  5.06802292e+01,  8.71998296e+00, -1.24764530e-01,\n",
       "       -4.83604275e+00,  6.14231211e+00,  2.21585950e+01,  3.12368810e-01,\n",
       "        1.24787716e+02,  8.55842876e+00, -1.17455236e+00,  6.34804531e+00,\n",
       "        3.15566422e+01,  7.51285268e+01, -3.83792721e+00,  2.96409376e-01,\n",
       "       -1.09754942e+00,  9.29674334e+01,  8.87035261e+00, -1.00502558e+00,\n",
       "        1.36549661e+01,  1.19408393e+00, -1.51921960e+00,  4.98465379e+00,\n",
       "        2.08549430e+01,  5.99499901e+01,  1.19435536e+01,  1.55519884e+01,\n",
       "        2.52176431e-01, -9.62662839e-01, -2.62364834e+00, -1.15421820e+00,\n",
       "        2.71449073e+01,  9.55348932e+00, -1.71881080e+00,  8.68118534e+01,\n",
       "        2.81008050e-01,  1.48106067e+01,  5.67885993e+01, -4.67902860e-01,\n",
       "       -9.01558747e-01,  2.97041310e-01,  4.21804977e+01, -3.31155195e+00,\n",
       "        3.33548807e-01,  1.36932438e-01, -5.43290160e-02, -6.58484560e-01,\n",
       "        9.52338239e+00,  7.27999634e+00,  1.35424500e+01,  7.00040591e+00,\n",
       "        1.78176990e+01,  2.81008050e-01,  6.75981556e+01,  3.31533250e+01,\n",
       "        3.05646915e-01,  9.77093719e+00,  1.24854868e+02,  2.84302361e-01,\n",
       "        1.49787873e+01,  2.29619407e+00, -2.71615830e+00, -4.50882968e-01,\n",
       "        2.51651905e+01,  3.03002500e-01,  4.71786548e+01,  1.12184922e+01,\n",
       "        4.13935814e+01,  2.45056920e-01,  1.86761094e+00,  9.95203274e+00,\n",
       "        2.81008050e-01,  2.00333454e+00, -3.34932524e+00,  1.08178601e+02,\n",
       "        5.02554043e+01,  4.13815963e+01, -1.56707753e+00,  1.25727736e+01,\n",
       "       -2.74764767e+00,  2.81168600e-01, -6.58484560e-01, -1.88354981e+00,\n",
       "        3.05184731e+01,  5.34785802e+00,  3.65182249e+01,  1.02049372e+01,\n",
       "       -1.57939967e+00, -5.00771505e+00, -1.23961447e+00,  3.89234030e+01,\n",
       "       -3.47155794e-02,  2.38437733e+00, -3.42780519e+00,  3.05646915e-01,\n",
       "       -2.77913704e+00,  9.43418706e+00,  4.13815963e+01,  8.99409506e+00,\n",
       "       -6.14483244e-01,  3.18366993e-01,  8.48319413e+00, -7.94869149e-01,\n",
       "        1.57402720e+00, -7.81243785e-01,  1.26967110e+01,  3.20895795e-01,\n",
       "       -1.10646420e+00])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_2a = adaBoost_2a.predict(X_test)\n",
    "y_predict_2a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 2 - Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees are based on the sine function and learn by "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=0, splitter='best')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "#Stock Model without AdaBoosting\n",
    "dec_tree_reg_2b_stock = DecisionTreeRegressor(random_state = 0)\n",
    "dec_tree_reg_2b_stock.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Regressor AdaBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=0, splitter='best'),\n",
       "         learning_rate=1.0, loss='linear', n_estimators=50, random_state=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Updated Model after AdaBoosting\n",
    "dec_tree_reg_2b_upt = DecisionTreeRegressor(random_state = 0)\n",
    "\n",
    "adaBoost_2b = AdaBoostRegressor(dec_tree_reg_2b_upt, random_state = 0)\n",
    "adaBoost_2b.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Regression AdaBoost Training Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Training Accuracy Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "print('AdaBoost Training Accuracy Score: {:.2f}'.format(adaBoost_2b.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Regression AdaBoost Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.452 ,   1.4232,   3.2472,  24.7264,   1.1768,   1.1768,\n",
       "         0.5124,   0.3496,   0.3944,   7.7956,   0.3944,   0.3724,\n",
       "        29.3736,   3.2472,   0.5124,   0.3724,  32.436 ,   1.1768,\n",
       "         0.5124,   0.3496,  22.9984,   4.2496,   0.3724,   1.0456,\n",
       "         1.32  ,   0.3724,  21.4896,   1.6632,   0.5124,   4.2496,\n",
       "         8.376 ,   0.3944,   2.4072,   0.3724,  16.3392,   5.3896,\n",
       "         0.356 ,  34.2384,   7.36  ,  12.8048,   1.0456,   0.3944,\n",
       "         0.3944,   1.516 ,   1.4712,   9.5656,   1.0456,   0.3724,\n",
       "         2.6328,  16.3392,   2.928 ,   0.5124,   0.3944,   2.928 ,\n",
       "         2.4348,   1.3476,  67.1308,   3.506 ,   1.1768,   2.928 ,\n",
       "         9.1248,  47.3616,   0.3944,   0.3724,   0.3944,  30.6276,\n",
       "         3.7068,   0.3724,   4.0896,   1.9076,   0.3944,   2.7048,\n",
       "        13.3564,  32.436 ,   7.9576,  10.3212,   0.3724,   0.3944,\n",
       "         0.3944,   1.3476,   1.4232,   4.2496,   0.3944, 116.7376,\n",
       "         0.3724,  11.0284,  21.4424,   0.3568,   0.3724,   0.5124,\n",
       "        16.8476,   1.32  ,   1.32  ,   0.5124,   1.32  ,   0.3944,\n",
       "         3.984 ,   5.036 ,  12.8048,   5.3896,   1.8552,   0.3724,\n",
       "        21.7536,  19.3752,   0.3496,   3.7068, 134.7624,   0.5124,\n",
       "        11.0284,   2.7048,   0.3944,   1.384 ,   2.4816,   0.5124,\n",
       "         4.2496,   3.506 ,   1.4232,   0.3944,   3.8332,   7.36  ,\n",
       "         0.3724,   2.5132,   1.0456,  25.4624,  22.1184,   1.32  ,\n",
       "         0.5124,   7.844 ,   0.3944,   0.3724,   0.3944,   0.3944,\n",
       "         3.984 ,   1.9768,   1.3428,   6.0868,   0.5124,   0.3944,\n",
       "         0.5124,   1.8552,   0.5124,   3.4644,   0.5124,   0.3496,\n",
       "         0.3944,   7.844 ,   1.32  ,   3.984 ,   0.5124,   0.3724,\n",
       "         2.9508,   0.3944,   1.9768,   0.5124,   3.276 ,   1.1768,\n",
       "         0.5124])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_2b = adaBoost_2b.predict(X_test)\n",
    "y_predict_2b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 - Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Support Vector Machine Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,\n",
       "     intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
       "     random_state=0, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Instantiating a stock Linear Support Vector Machine Regression Model\n",
    "svm_reg_3_stock = LinearSVR(random_state = 0)\n",
    "svm_reg_3_stock.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear SVM with Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to LinearSVR.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-3729c62920bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#LinearSVR after Gradient Boosting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msvm_reg_3_upt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradientBoostingRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvm_reg_3_stock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msvm_reg_3_upt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    990\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 991\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    992\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_check_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    815\u001b[0m         if (self.loss not in self._SUPPORTED_LOSS\n\u001b[0;32m    816\u001b[0m                 or self.loss not in LOSS_FUNCTIONS):\n\u001b[1;32m--> 817\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Loss '{0:s}' not supported. \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'deviance'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported format string passed to LinearSVR.__format__"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "#LinearSVR after Gradient Boosting\n",
    "svm_reg_3_upt = GradientBoostingRegressor(svm_reg_3_stock, random_state = 0)\n",
    "svm_reg_3_upt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 - Principle Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting Dataset\n",
    "X_train_org , X_test_org, y_train, y_test = train_test_split(X, y, test_size = 0.15, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling the Data for PCA using MinMaxScaler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determining number of Principle Components using Elbow Curve\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "prin_comps = pca.fit_transform(X_train)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Principle Component Analysis\n",
    "\n",
    "pca = PCA(n_components = 8)\n",
    "prin_comps_train = pca.fit_transform(X_train)\n",
    "prin_comps_test = pca.transform(X_test)\n",
    "#PCA Characteristics\n",
    "pca.components_\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project 1 Results Before PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Type</th>\n",
       "      <th>Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Model Type, Results]\n",
       "Index: []"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating Project 1 Results Table\n",
    "p1_data = [['KNN Regressor', ]]\n",
    "proj_1_res = pd.DataFrame(columns = ['Model Type', 'Results'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 - Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srohi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Neural Network Packages\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resetting the train_test_split\n",
    "\n",
    "X_train_neuro, X_test_neuro, y_train_neuro, y_test_neuro = train_test_split(X, y, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(625, 31)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearch to find parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "468/468 [==============================] - 1s 1ms/step - loss: 112.1138 - acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "468/468 [==============================] - 0s 6us/step - loss: 108.6755 - acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "468/468 [==============================] - 0s 6us/step - loss: 105.1536 - acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "468/468 [==============================] - 0s 7us/step - loss: 101.6324 - acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "468/468 [==============================] - 0s 7us/step - loss: 98.2088 - acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "468/468 [==============================] - 0s 6us/step - loss: 94.6728 - acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: 91.0220 - acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "468/468 [==============================] - 0s 6us/step - loss: 85.7821 - acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: 78.8823 - acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: 71.4215 - acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: 63.8622 - acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: 56.1981 - acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: 49.3478 - acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: 44.8048 - acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: 40.3228 - acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: 36.9117 - acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: 33.9895 - acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: 31.3515 - acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: 28.8011 - acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "468/468 [==============================] - 0s 3us/step - loss: 26.2702 - acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: 23.8172 - acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: 21.4701 - acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: 19.2042 - acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: 17.0303 - acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: 14.9699 - acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: 13.0596 - acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "468/468 [==============================] - 0s 3us/step - loss: 11.1433 - acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "468/468 [==============================] - 0s 3us/step - loss: 9.2175 - acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: 7.4371 - acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: 5.5811 - acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: 3.9590 - acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: 2.3405 - acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: 0.7438 - acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: -0.7883 - acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -2.3772 - acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -3.9770 - acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -5.5500 - acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: -7.1275 - acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -8.7215 - acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -10.2775 - acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -11.8495 - acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -13.4663 - acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -15.0549 - acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: -16.6762 - acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -18.3348 - acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "468/468 [==============================] - 0s 3us/step - loss: -20.0137 - acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: -21.6725 - acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: -23.3663 - acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -25.0284 - acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -26.6639 - acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -28.3239 - acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -29.9466 - acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -31.5269 - acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: -33.1729 - acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: -34.7411 - acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -36.2780 - acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -37.7880 - acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -39.2651 - acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: -40.6461 - acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -42.0280 - acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -43.6107 - acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -62.2688 - acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -84.2999 - acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -104.6981 - acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: -114.8796 - acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: -116.0964 - acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -117.2384 - acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -118.2818 - acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "468/468 [==============================] - 0s 1us/step - loss: -119.3049 - acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -120.1887 - acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -121.0394 - acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -121.8135 - acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: -122.5369 - acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -123.2886 - acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -123.9721 - acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: -124.5357 - acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -125.0963 - acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -125.6383 - acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: -126.0901 - acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -126.6222 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "468/468 [==============================] - 0s 1us/step - loss: -126.9682 - acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -127.4274 - acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: -127.8024 - acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "468/468 [==============================] - 0s 3us/step - loss: -128.0641 - acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "468/468 [==============================] - 0s 3us/step - loss: -128.4473 - acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "468/468 [==============================] - 0s 3us/step - loss: -128.7914 - acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -128.9696 - acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: -129.2589 - acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: -129.4400 - acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: -129.7664 - acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -129.9173 - acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: -130.0813 - acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "468/468 [==============================] - 0s 3us/step - loss: -130.2127 - acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: -130.3623 - acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: -130.4825 - acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: -130.6510 - acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -130.7719 - acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -130.8751 - acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "468/468 [==============================] - 0s 2us/step - loss: -130.9953 - acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "468/468 [==============================] - 0s 4us/step - loss: -131.1192 - acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c0fee04e80>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Instantiating the model\n",
    "neuro_model_1 = Sequential()\n",
    "#Input Layer\n",
    "neuro_model_1.add(Dense(10, input_dim = 31, activation = 'relu'))\n",
    "#Output Layer\n",
    "neuro_model_1.add(Dense(1, activation = 'sigmoid'))\n",
    "#Creates computational graph\n",
    "neuro_model_1.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "#Training the model and setting epoch and batch size\n",
    "neuro_model_1.fit(X_train_neuro, y_train_neuro, epochs = 100, batch_size = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron - With hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiating MLP\n",
    "neuro_model_2 = Sequential()\n",
    "\n",
    "#Input Layer\n",
    "neuro_model_2.add(Dense(20, input_dim = 31, activation = 'relu'))\n",
    "\n",
    "#Hidden Layer 1\n",
    "neuro_model_2.add(Dense(10, activation = 'relu'))\n",
    "#Hidden Layer 2\n",
    "neuro_model_2.add(Dense(5, activation = 'relu'))\n",
    "\n",
    "#Output Layer\n",
    "neuro_model_2.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "#Computational Graph\n",
    "neuro_model_2.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "neuro_model_2.fit(X_train_neuro, y_train_neuro, epochs = 30, batch_size = 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 - Voting Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting X and y values\n",
    "Xc = df.drop(['Audit_Risk', 'Risk'], axis = 1)\n",
    "yc = df['Audit_Risk']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1.714800\n",
       "1       0.510800\n",
       "2       0.309600\n",
       "3       3.506000\n",
       "4       0.283200\n",
       "5       0.431200\n",
       "6       6.354800\n",
       "7       3.606800\n",
       "8       3.441200\n",
       "10      2.400800\n",
       "11     21.422400\n",
       "12      5.756800\n",
       "14      0.313880\n",
       "15      1.876800\n",
       "16     20.268000\n",
       "17      2.898400\n",
       "19     14.298400\n",
       "20     13.824000\n",
       "22     56.709600\n",
       "23      0.322000\n",
       "24      9.263200\n",
       "25      1.310000\n",
       "26      0.324280\n",
       "27      4.971600\n",
       "28      0.321200\n",
       "30      2.610000\n",
       "31     18.571200\n",
       "32      0.393600\n",
       "33      0.512400\n",
       "34      0.297200\n",
       "         ...    \n",
       "772     0.280000\n",
       "774     0.284000\n",
       "775     2.423600\n",
       "776     0.290068\n",
       "777     0.292460\n",
       "778     0.280000\n",
       "779     0.313600\n",
       "782     0.315200\n",
       "783     0.283600\n",
       "784     0.332000\n",
       "786     0.280000\n",
       "788     0.321600\n",
       "789     0.339600\n",
       "791     0.280000\n",
       "792     0.280000\n",
       "793     0.280000\n",
       "794     0.280000\n",
       "795     0.303600\n",
       "796     0.280800\n",
       "799     0.334800\n",
       "800     0.324400\n",
       "801     0.318800\n",
       "802     0.324000\n",
       "803     0.328000\n",
       "804     0.315600\n",
       "805     0.315600\n",
       "806     0.313600\n",
       "807     0.291200\n",
       "808     0.288000\n",
       "809     0.292800\n",
       "Name: Audit_Risk, Length: 625, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "#Spliting the dataset with train_test_split\n",
    "\n",
    "#X_train_origC, X_test_origC, y_train_cls, y_test_cls = train_test_split(X, y, random_state = 0)\n",
    "X_train_cls, X_test_cls, y_train_cls, y_test_cls = train_test_split(Xc, yc, random_state = 0)\n",
    "\n",
    "#Scaling the data with MinMaxScaler\n",
    "\n",
    "#class_scaler = MinMaxScaler()\n",
    "#X_train_cls = class_scaler.fit_transform(X_train_origC)\n",
    "#X_test_cls = class_scaler.transform(X_test_origC)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Label Encoder to substitute integer values for floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([2.800000e-01, 2.806800e-01, 2.808000e-01, 2.812000e-01,\n",
       "       2.820000e-01, 2.824000e-01, 2.828000e-01, 2.832000e-01,\n",
       "       2.836000e-01, 2.840000e-01, 2.844000e-01, 2.860000e-01,\n",
       "       2.868000e-01, 2.876000e-01, 2.880000e-01, 2.884000e-01,\n",
       "       2.892000e-01, 2.896000e-01, 2.900680e-01, 2.904000e-01,\n",
       "       2.904840e-01, 2.908680e-01, 2.912000e-01, 2.916000e-01,\n",
       "       2.920000e-01, 2.920920e-01, 2.924000e-01, 2.924600e-01,\n",
       "       2.928000e-01, 2.928360e-01, 2.932000e-01, 2.961000e-01,\n",
       "       2.964000e-01, 2.968000e-01, 2.972000e-01, 2.976000e-01,\n",
       "       2.980000e-01, 2.988000e-01, 2.992000e-01, 2.996000e-01,\n",
       "       3.000000e-01, 3.004000e-01, 3.008000e-01, 3.016000e-01,\n",
       "       3.024000e-01, 3.032000e-01, 3.036000e-01, 3.040000e-01,\n",
       "       3.044000e-01, 3.048000e-01, 3.052000e-01, 3.060000e-01,\n",
       "       3.072000e-01, 3.076000e-01, 3.080000e-01, 3.084000e-01,\n",
       "       3.092000e-01, 3.096000e-01, 3.104000e-01, 3.112000e-01,\n",
       "       3.120000e-01, 3.124000e-01, 3.128000e-01, 3.132000e-01,\n",
       "       3.136000e-01, 3.140000e-01, 3.144000e-01, 3.152000e-01,\n",
       "       3.156000e-01, 3.164000e-01, 3.168000e-01, 3.172000e-01,\n",
       "       3.180000e-01, 3.184000e-01, 3.188000e-01, 3.192000e-01,\n",
       "       3.208000e-01, 3.212000e-01, 3.216000e-01, 3.220000e-01,\n",
       "       3.224000e-01, 3.236000e-01, 3.240000e-01, 3.242800e-01,\n",
       "       3.244000e-01, 3.260000e-01, 3.264000e-01, 3.296000e-01,\n",
       "       3.300000e-01, 3.308000e-01, 3.312000e-01, 3.320000e-01,\n",
       "       3.340000e-01, 3.348000e-01, 3.372000e-01, 3.376000e-01,\n",
       "       3.396000e-01, 3.400000e-01, 3.412000e-01, 3.416000e-01,\n",
       "       3.432000e-01, 3.448000e-01, 3.456000e-01, 3.468000e-01,\n",
       "       3.480000e-01, 3.496000e-01, 3.512000e-01, 3.524000e-01,\n",
       "       3.536000e-01, 3.552000e-01, 3.560000e-01, 3.568000e-01,\n",
       "       3.724000e-01, 3.888000e-01, 3.900000e-01, 3.936000e-01,\n",
       "       3.940000e-01, 3.944000e-01, 4.056000e-01, 4.120000e-01,\n",
       "       4.184000e-01, 4.312000e-01, 4.448000e-01, 4.532000e-01,\n",
       "       5.124000e-01, 1.027200e+00, 1.045600e+00, 1.074400e+00,\n",
       "       1.118400e+00, 1.142000e+00, 1.143200e+00, 1.157200e+00,\n",
       "       1.157600e+00, 1.161600e+00, 1.176800e+00, 1.214800e+00,\n",
       "       1.234800e+00, 1.261200e+00, 1.266800e+00, 1.286800e+00,\n",
       "       1.316000e+00, 1.320000e+00, 1.329600e+00, 1.336800e+00,\n",
       "       1.342800e+00, 1.347600e+00, 1.384000e+00, 1.384800e+00,\n",
       "       1.398000e+00, 1.402800e+00, 1.423200e+00, 1.429600e+00,\n",
       "       1.452000e+00, 1.471200e+00, 1.496400e+00, 1.498800e+00,\n",
       "       1.516000e+00, 1.537600e+00, 1.576800e+00, 1.594800e+00,\n",
       "       1.603200e+00, 1.609200e+00, 1.610400e+00, 1.663200e+00,\n",
       "       1.679200e+00, 1.687200e+00, 1.708800e+00, 1.714800e+00,\n",
       "       1.782000e+00, 1.830400e+00, 1.855200e+00, 1.876800e+00,\n",
       "       1.907600e+00, 1.922000e+00, 1.976800e+00, 2.040400e+00,\n",
       "       2.216400e+00, 2.252800e+00, 2.368800e+00, 2.400800e+00,\n",
       "       2.407200e+00, 2.424000e+00, 2.434800e+00, 2.481600e+00,\n",
       "       2.513200e+00, 2.610000e+00, 2.632800e+00, 2.704800e+00,\n",
       "       2.716400e+00, 2.821600e+00, 2.869200e+00, 2.887200e+00,\n",
       "       2.928000e+00, 2.950800e+00, 3.032400e+00, 3.247200e+00,\n",
       "       3.276000e+00, 3.464400e+00, 3.486000e+00, 3.506000e+00,\n",
       "       3.516800e+00, 3.602000e+00, 3.606800e+00, 3.636000e+00,\n",
       "       3.706800e+00, 3.771600e+00, 3.833200e+00, 3.850800e+00,\n",
       "       3.874400e+00, 3.978000e+00, 3.982000e+00, 3.984000e+00,\n",
       "       4.013600e+00, 4.089600e+00, 4.094800e+00, 4.123200e+00,\n",
       "       4.161600e+00, 4.232000e+00, 4.249600e+00, 4.312800e+00,\n",
       "       4.889200e+00, 4.903200e+00, 4.944400e+00, 4.962000e+00,\n",
       "       4.971600e+00, 5.036000e+00, 5.273200e+00, 5.389600e+00,\n",
       "       5.756800e+00, 5.819200e+00, 5.878000e+00, 6.036000e+00,\n",
       "       6.086800e+00, 6.425200e+00, 6.469200e+00, 6.522000e+00,\n",
       "       6.528000e+00, 7.147200e+00, 7.159600e+00, 7.360000e+00,\n",
       "       7.506400e+00, 7.795600e+00, 7.841200e+00, 7.844000e+00,\n",
       "       7.957600e+00, 8.066800e+00, 8.120800e+00, 8.376000e+00,\n",
       "       8.387200e+00, 8.425600e+00, 8.505600e+00, 8.545600e+00,\n",
       "       8.580000e+00, 8.608000e+00, 8.962800e+00, 9.026800e+00,\n",
       "       9.122800e+00, 9.124800e+00, 9.263200e+00, 9.343600e+00,\n",
       "       9.565600e+00, 9.670800e+00, 9.810400e+00, 9.883600e+00,\n",
       "       9.949200e+00, 1.011040e+01, 1.032120e+01, 1.055800e+01,\n",
       "       1.087560e+01, 1.102840e+01, 1.105440e+01, 1.113120e+01,\n",
       "       1.138840e+01, 1.162360e+01, 1.206760e+01, 1.223760e+01,\n",
       "       1.279680e+01, 1.280480e+01, 1.325600e+01, 1.335640e+01,\n",
       "       1.384360e+01, 1.412920e+01, 1.429840e+01, 1.459120e+01,\n",
       "       1.474720e+01, 1.515120e+01, 1.525160e+01, 1.568320e+01,\n",
       "       1.633920e+01, 1.644520e+01, 1.680640e+01, 1.684760e+01,\n",
       "       1.713120e+01, 1.726120e+01, 1.739760e+01, 1.818960e+01,\n",
       "       1.857120e+01, 1.860560e+01, 1.937400e+01, 1.937520e+01,\n",
       "       1.998920e+01, 2.126640e+01, 2.132720e+01, 2.144240e+01,\n",
       "       2.148960e+01, 2.175360e+01, 2.187760e+01, 2.200000e+01,\n",
       "       2.211840e+01, 2.232480e+01, 2.299840e+01, 2.308320e+01,\n",
       "       2.472640e+01, 2.546240e+01, 2.937360e+01, 3.062760e+01,\n",
       "       3.217440e+01, 3.243600e+01, 3.328200e+01, 3.364880e+01,\n",
       "       3.389040e+01, 3.423840e+01, 3.492960e+01, 3.598320e+01,\n",
       "       3.719260e+01, 4.456920e+01, 4.483360e+01, 4.535680e+01,\n",
       "       4.598400e+01, 4.736160e+01, 5.572640e+01, 5.595200e+01,\n",
       "       5.670960e+01, 5.733280e+01, 6.176760e+01, 6.298560e+01,\n",
       "       6.713080e+01, 6.874320e+01, 8.252480e+01, 1.167376e+02,\n",
       "       1.245676e+02, 1.347624e+02, 1.498176e+02, 2.220096e+02,\n",
       "       9.615144e+02])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_train_cls)\n",
    "le.classes_\n",
    "lab_encode_tr = le.transform(y_train_cls)\n",
    "#list(le.classes_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([  0.28    ,   0.2804  ,   0.2808  ,   0.2824  ,   0.2836  ,\n",
       "         0.2852  ,   0.288   ,   0.2884  ,   0.2888  ,   0.2912  ,\n",
       "         0.293252,   0.294   ,   0.2964  ,   0.2972  ,   0.2988  ,\n",
       "         0.3012  ,   0.3048  ,   0.308   ,   0.3124  ,   0.3128  ,\n",
       "         0.3132  ,   0.31388 ,   0.3148  ,   0.3156  ,   0.3168  ,\n",
       "         0.3184  ,   0.3192  ,   0.32    ,   0.3216  ,   0.3244  ,\n",
       "         0.3276  ,   0.328   ,   0.3284  ,   0.3312  ,   0.332   ,\n",
       "         0.3356  ,   0.3364  ,   0.3368  ,   0.338   ,   0.3476  ,\n",
       "         0.35    ,   0.3756  ,   0.3976  ,   0.402   ,   0.4228  ,\n",
       "         0.4756  ,   0.4948  ,   0.5108  ,   1.0144  ,   1.0592  ,\n",
       "         1.1128  ,   1.2988  ,   1.3076  ,   1.31    ,   1.32    ,\n",
       "         1.3812  ,   1.3908  ,   1.4088  ,   1.4436  ,   1.4592  ,\n",
       "         1.4764  ,   1.5308  ,   1.5516  ,   1.568   ,   1.572   ,\n",
       "         1.586472,   1.5904  ,   1.6116  ,   1.6816  ,   1.758   ,\n",
       "         1.7672  ,   2.21    ,   2.2216  ,   2.4236  ,   2.4716  ,\n",
       "         2.5356  ,   2.5376  ,   2.688   ,   2.8984  ,   2.9056  ,\n",
       "         2.9856  ,   3.0332  ,   3.258   ,   3.4412  ,   3.5752  ,\n",
       "         3.692   ,   3.9464  ,   3.9772  ,   4.5132  ,   4.6592  ,\n",
       "         4.6924  ,   5.2776  ,   5.7736  ,   6.0544  ,   6.3548  ,\n",
       "         6.572   ,   7.0924  ,   7.2184  ,   7.9512  ,   9.1172  ,\n",
       "         9.3468  ,  10.0688  ,  10.5516  ,  10.9028  ,  11.1928  ,\n",
       "        12.7652  ,  13.186   ,  13.824   ,  17.7664  ,  18.7368  ,\n",
       "        19.6304  ,  20.268   ,  21.4224  ,  21.6724  ,  22.6292  ,\n",
       "        23.77    ,  25.2576  ,  27.4032  ,  27.6168  ,  32.658   ,\n",
       "        39.0624  ,  45.2368  ,  52.012   ,  57.284   ,  67.8172  ,\n",
       "       115.5016  , 204.7808  ])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Label Encoding the Testing Set\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_test_cls)\n",
    "le.classes_\n",
    "lab_encode_te = le.transform(y_test_cls)\n",
    "#list(le.classes_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_cls = KNeighborsClassifier(3)\n",
    "knn_cls.fit(X_train_cls, lab_encode)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_cls = LogisticRegression(penalty = 'l2', C = 0.1)\n",
    "log_cls.fit(X_train_cls, lab_encode)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Support Vector Machine Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm_cls = LinearSVC(C=1)\n",
    "svm_cls.fit(X_train_cls, lab_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('KNN', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')), ('Log Reg', LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scali...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))],\n",
       "         flatten_transform=None, n_jobs=1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hard Voting Classifier\n",
    "voting_cls_hard = VotingClassifier(estimators = [('KNN', knn_cls), ('Log Reg', log_cls), ('Sup Vec', svm_cls)], voting = 'hard')\n",
    "voting_cls_hard.fit(X_train_cls, lab_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hard Voting Classifier Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score KNeighborsClassifier 0.12101910828025478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score LogisticRegression 0.12101910828025478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score LinearSVC 0.12101910828025478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('KNN', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')), ('Log Reg', LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scali...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))],\n",
       "         flatten_transform=None, n_jobs=1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score VotingClassifier 0.12101910828025478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srohi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "#Prediction for hard Voting CLassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "for cls in (knn_cls, log_cls, svm_cls, voting_cls_hard):\n",
    "    cls.fit(X_train_cls, lab_encode)\n",
    "    y_pred_hard = cls.predict(X_test_cls)\n",
    "    print('Accuracy Score', cls.__class__.__name__, accuracy_score(lab_encode_te, y_pred_cls))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('KNN', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')), ('Log Reg', LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scali...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))],\n",
       "         flatten_transform=None, n_jobs=1, voting='soft', weights=None)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Soft Voting Classifier\n",
    "voting_cls_soft = VotingClassifier(estimators = [('KNN', knn_cls), ('Log Reg', log_cls), ('Sup Vec', svm_cls)], voting = 'soft')\n",
    "voting_cls_soft.fit(X_train_cls, lab_encode_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score KNeighborsClassifier 0.12101910828025478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score LogisticRegression 0.12101910828025478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('KNN', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')), ('Log Reg', LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scali...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))],\n",
       "         flatten_transform=None, n_jobs=1, voting='soft', weights=None)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "AttributeError",
     "evalue": "'LinearSVC' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-b6e9dd6891be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mknn_cls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_cls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvoting_cls_soft\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_cls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlab_encode_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0my_pred_soft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_cls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy Score'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlab_encode_te\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_cls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\voting_classifier.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'estimators_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvoting\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'soft'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m             \u001b[0mmaj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# 'hard' voting\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\voting_classifier.py\u001b[0m in \u001b[0;36m_predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    239\u001b[0m                                  \" voting=%r\" % self.voting)\n\u001b[0;32m    240\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'estimators_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m         avg = np.average(self._collect_probas(X), axis=0,\n\u001b[0m\u001b[0;32m    242\u001b[0m                          weights=self._weights_not_none)\n\u001b[0;32m    243\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mavg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\voting_classifier.py\u001b[0m in \u001b[0;36m_collect_probas\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_collect_probas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;34m\"\"\"Collect results from clf.predict calls. \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_predict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\voting_classifier.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_collect_probas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;34m\"\"\"Collect results from clf.predict calls. \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_predict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LinearSVC' object has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "#Prediction for Soft Voting Classifier\n",
    "for cls in (knn_cls, log_cls, svm_cls, voting_cls_soft):\n",
    "    cls.fit(X_train_cls, lab_encode_tr)\n",
    "    y_pred_soft = cls.predict(X_test_cls)\n",
    "    print('Accuracy Score', cls.__class__.__name__, accuracy_score(lab_encode_te, y_pred_cls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 - Bagging and Pasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging with Linear Support Vector Machine Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "grid_search = GridSearchCV(LinearSVC(), param_grid, cv=5, return_train_score=True)\n",
    "grid_search.fit(X_train_cls, y_train_cls)\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiating the Bagging Classifier package\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bagging_cls_1a = BaggingClassifier(LinearSVC(C = 100, random_state = 0), bootstrap = True, n_jobs = -1, random_state = 0)\n",
    "\n",
    "bagging_cls_1a.fit(X_train_cls, y_train_cls)\n",
    "LinSVC1a = bagging_cls_1a.predict(X_test_cls)\n",
    "LinSVC1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Bagging Training Score for Linear Support Vector Regressor: {:.2f}'.format(bagging_cls_1a.score(X_train_cls, y_train_cls)))\n",
    "print('Bagging Testing Score for Linear Support Vector Regressor: {:.2f}'.format(bagging_cls_1a.score(X_test_cls, y_test_cls)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PASTING\n",
    "\n",
    "pasting_cls_1b = BaggingClassifier(LinearSVC(C = 100, random_state = 0), bootstrap = False, n_jobs = -1, random_state = 0)\n",
    "\n",
    "pasting_cls_1b.fit(X_train_cls, y_train_cls)\n",
    "LinSVC_1b = pasting_cls_1b.predict(X_test_cls)\n",
    "LinSVC_1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Pasting Training Score for Linear Support Vector Regressor: {:.2f}'.format(pasting_cls_1b.score(X_train_cls, y_train_cls)))\n",
    "print('Pasting Testing Score for Linear Support Vector Regressor: {:.2f}'.format(pasting_cls_1b.score(X_test_cls, y_test_cls)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithm 2 - RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_cls_1c = RandomForestClassifier(max_leaf_nodes = 20, random_state = 0)\n",
    "bagging_cls_1c = BaggingClassifier(forest_cls_1c, n_estimators = 10, bootstrap = True)\n",
    "\n",
    "bagging_cls_1c.fit(X_train_cls, y_train_cls)\n",
    "forest_pred_1c = bagging_cls_1c.predict(X_test_cls)\n",
    "forest_pred_1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Bagging Training Score for Linear Support Vector Regressor: {:.2f}'.format(bagging_cls_1c.score(X_train_cls, y_train_cls)))\n",
    "print('Bagging Testing Score for Linear Support Vector Regressor: {:.2f}'.format(bagging_cls_1c.score(X_test_cls, y_test_cls)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_cls_1d = RandomForestRegressor(max_leaf_nodes = 20, random_state = 0)\n",
    "pasting_cls_1d = BaggingRegressor(forest_cls_1d, n_estimators = 10, bootstrap = False, n_jobs = -1, random_state = 0)\n",
    "\n",
    "#Fitting the Bagging Regressor\n",
    "pasting_cls_1d.fit(X_train_cls, y_train_cls)\n",
    "forest_pred_1d = pasting_cls_1d.predict(X_test_cls)\n",
    "forest_pred_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Pasting Training Score for Linear Support Vector Regressor: {:.2f}'.format(pasting_cls_1d.score(X_train_cls, y_train_cls)))\n",
    "print('Pasting Testing Score for Linear Support Vector Regressor: {:.2f}'.format(pasting_cls_1d.score(X_test_cls, y_test_cls)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 - AdaBoosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 1 - Linear Support Vector Machine - Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVR uses only a subset of training data - any data near the prediction of the model\n",
    "\n",
    "Uses decision boundaries and a hyperplane in classification of data. Linear SVC performs faster and allows for more manipulation of options than SVC with linear kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiating the LInear Support Vector Classification Package\n",
    "from sklearn.svm import LinearSVC\n",
    "#Stock Model without AdaBoosting\n",
    "svm_cls_2a_stock = LinearSVC(random_state = 0)\n",
    "svm_cls_2a_stock.fit(X_train_cls, y_train_cls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Characteristics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regression Equation Coefficient\n",
    "print('Support Vector Classification Coefficients: ', svm_cls_2a_stock.coef_)\n",
    "#Regression Equation Intercept\n",
    "print('Support Vector Classification Intercept:',svm_cls_2a_stock.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearSVR AdaBoosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying AdaBoosting to LinearSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "#Updated Model after AdaBoosting\n",
    "svm_cls_2a_upt = LinearSVC(random_state = 0)\n",
    "\n",
    "adaBoost_cls_2a = AdaBoostRegressor(svm_cls_2a_upt, random_state = 0)\n",
    "adaBoost_cls_2a.fit(X_train_cls, y_train_cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the Decision Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Support Vector Classifier AdaBoost Training Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('AdaBoost Training Accuracy Score: {:.2f}'.format(adaBoost_cls_2a.score(X_train_cls, y_train_cls)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear SVR AdaBoost Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_predict_2a = adaBoost_cls_2a.predict(X_test_cls)\n",
    "ada_predict_2a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 2 - Decision Tree  - Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees are based on the sine function and learn by "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#Stock Model without AdaBoosting\n",
    "dec_tree_cls_2b_stock = DecisionTreeRegressor(random_state = 0)\n",
    "dec_tree_cls_2b_stock.fit(X_train_cls, y_train_cls)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Regressor AdaBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updated Model after AdaBoosting\n",
    "dec_tree_cls_2b_upt = DecisionTreeClassifier(random_state = 0)\n",
    "\n",
    "adaBoost_cls_2b = AdaBoostClassifier(dec_tree_cls_2b_upt, random_state = 0)\n",
    "adaBoost_cls_2b.fit(X_train_cls, y_train_cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Regression AdaBoost Training Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('AdaBoost Training Accuracy Score: {:.2f}'.format(adaBoost_cls_2b.score(X_train_cls, y_train_cls)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Regression AdaBoost Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_predict_2b = adaBoost_cls_2b.predict(X_test_cls)\n",
    "ada_predict_2b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 - Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Support Vector Machine Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#Instantiating a stock Linear Support Vector Machine Regression Model\n",
    "svm_cls_3_stock = LinearSVC(random_state = 0)\n",
    "svm_cls_3_stock.fit(X_train, y_train)\n",
    "#Creating the Gradient Boosting Model\n",
    "gboost_cls = GradientBoostingRegressor(random_state = 0)\n",
    "#Fitting the model to the training data\n",
    "gboost_cls.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and Testing fit scores\n",
    "print(\"Training Accuracy: {:.3f}\".format(gboost_cls.score(X_train, y_train)))\n",
    "print(\"Testing Accuracy: {:.3f}\".format(gboost_cls.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 - Principle Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling the Data for PCA using Standard Scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std_cls_scaler = StandardScaler()\n",
    "X_train_pca = std_scaler.fit_transform(X_train_orig)\n",
    "X_test_pca = std_scaler.transform(X_test_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_cls = PCA()\n",
    "#Determining number of Principle Components using Elbow Curve\n",
    "\n",
    "prin_comps = pca_cls.fit_transform(X_train_pca)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Principle Component Analysis\n",
    "\n",
    "pca_cls = PCA(n_components = 8)\n",
    "prin_comps_train = pca.fit_transform(X_train_pca)\n",
    "prin_comps_test = pca.transform(X_test_pca)\n",
    "#PCA Characteristics\n",
    "pca.components_\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6 - Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiating the model\n",
    "neuro_cls_1 = Sequential()\n",
    "#Input Layer\n",
    "neuro_cls_1.add(Dense())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
